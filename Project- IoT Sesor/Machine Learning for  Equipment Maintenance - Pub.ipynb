{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Machine Learning for Equipment Failure Prediction and Equipment Maintenance (PM)"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "For more information on the topic please see the following article.\n\nhttps://medium.com/swlh/machine-learning-for-equipment-failure-prediction-and-predictive-maintenance-pm6/\n\n\nPublished July 2020, Greatly revised on February 2021."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "In this notebook, I walk through a predictive maintenance problem in great detail.  These types of issues can be tricky for several reasons.  The first six sections deal with building a model.  The last sections deal with evaluating model effectiveness and ensuring it will be effective when deployed in production.\n\n\nWhen it comes to dealing with machines that require periodic maintenance, there are generally three possible outcomes.\n\nOne, you can maintain a machine too frequently. In other words, the machine gets maintenance when it is not required. In this scenario, you are throwing money out the window, wasting resources providing unnecessary maintenance. For example, you could change the oil in your car every single day. This is not optimal, and you will waste a lot of money on unnecessary maintenance.\n\nTwo, you don\u2019t maintain your machine frequently enough. Failing to maintain a machine means that the machine will break while operating. Here, the costs could be substantial. Not only do you have the repair costs, but also costs associated with lost production. If a machine on the assembly line goes down, the line cannot produce anything. No production means lost profit. Also, you will incur legal and medical costs if injuries occurred as a result of the failure.\n\nThree, a machine is maintained when it needs maintenance. This is obviously the better alternative of the three. Note, that that there is still a cost associated with timely maintenance.\n\nSo, we need to maintain machines when they need maintenance, right? Unfortunately, this is easier said than done. Fortunately, we can use predictive maintenance (PM) to predict when machines need maintenance.\n\nI should also mention that most machines come with manufacturer recommendations on maintenance. The problem with manufacturer recommendations is that they represent an average. For example, cars on average need an oil change every 3,000 miles, but how frequently does your car need an oil change? It may be more or less than 3,000 miles depending on several factors, including where your drive, how you drive, and how frequently you drive.\n\nPredictive maintenance (PM) can tell you, based on data, when a machine requires maintenance. An effective PM program will minimize under and over-maintaining your machine. For a large manufacturer with thousands of machines, being precise on machine maintenance can save millions of dollars every year.\n\nIn this article, I will examine a typical Predictive Maintenance (PM) use case. As I walk through this example, I will describe some of the issues that arise with PM problems and suggest ways to solve them.\n\nAn important note about the data used in this exercise. It is entirely fake. I created the data based on my experience of dealing with these types of problems. Although it is entirely artificial, I believe the data and use case is very realistic and consistent with many real PM problems.\n\n\n\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The firm in our use case provided a sample of data that includes 421 machines that failed over two years. They spent 11.766M dollars on maintenance, most of which came from running machines until failure.\n\nHere is a summary of the maintained or repaired machines over the last two years."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from IPython.display import Image\nfrom IPython.core.display import HTML \nImage(url= \"https://cdn-images-1.medium.com/max/1600/1*fUKUEUeqgIYU9xlxj4pwhw.png\")",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 1,
                    "data": {
                        "text/html": "<img src=\"https://cdn-images-1.medium.com/max/1600/1*fUKUEUeqgIYU9xlxj4pwhw.png\"/>",
                        "text/plain": "<IPython.core.display.Image object>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "From the data above, it currently costs the firm about $28,000 per failed or maintained machine. Our goal is to lower this cost.\n\nIn the chart above, Timely Maintenance costs more than Unnecessary Maintenance. There is a good reason for this. For this machine, unnecessary maintenance means that that machine was moved off-line and checked, but the part in question showed insufficient wear to replace. Because parts were not replaced, there are no material costs, only labor.\n\nNote that this company does very little predictive maintenance. Most of the time, they just run the machines to failure. Also, note that these machines will break in four to eight years if they don\u2019t receive maintenance. When they fail, they must be pulled off-line and repaired.\n\nOur goal is to show the firm how a Predictive Maintenance program can save them money. To do this, we will build a predictive model that predicts machine failure within 90 days of actual failure. Note that an appropriate failure window will always depend on the context of the problem. If a machine breaks without maintenance in 6 months, a three-month window makes no sense. Here, where a machine will run between 4 to 6 years without maintenance, a 90-day window is reasonable.\n\nOur objective is to develop a solution that will lower the costs of failure. Again, it currently costs the firm about 28,000 per machine. We will attempt to reduce this cost.\n\nNote that I developed this exercise in Watson Studio on the IBM Cloud.  If you have issues running the notebook, please set up a free account on IBM Cloud and try it there.\nhttps://www.ibm.com/cloud/watson-studio\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Table of Contents"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "1. [Getting Setup](#setup1)<br>\n \n2. [Data Exploration](#explore)<br>\n\n3. [Data Transformation and Feature Engineering](#trans)<br>\n \n4. [Dealing with the Small Number of Failures](#small)<br>\n    4.1 [Expand the Failure Window](#window)<br>\n    4.2 [Create Testing, Training and Validation Groups](#groups)<br>\n    4.3 [SMOTE the Training Data](#smote)<br>\n5. [More Data Transformations and Feature Engineering](#more)<br>\n6. [Build the Model on the Balanced Data Set](#build)<br>\n7. [Evaluate model on the unbalanced training and testing data set](#score)<br>\n    7.1 [Evaluate the model using an AUC and accuacy metrics](#7.1)<br>\n    7.2 [Evaluating with a Confusion Matrix](#7.2)<br>\n    7.3 [Using Heuristics to Define a False Positive, True Positive, False Negative and True Negative](#7.3)<br>\n    7.4 [7.4 Apply Model and Heuristics the Training, Testing and Validation Data Sets](#7.4)<br>\n11. [Conclusions](#conc)<br>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 1.0 Getting Set-Up <a id=\"setup1\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": " Install all of the relevant Python Libraries"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\n!pip install imblearn --upgrade\n!pip install plotly --upgrade\n!pip install chart-studio --upgrade\n\n\n",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Requirement already up-to-date: imblearn in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (0.0)\nRequirement already satisfied, skipping upgrade: imbalanced-learn in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from imblearn) (0.7.0)\nRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.5.0)\nRequirement already satisfied, skipping upgrade: scikit-learn>=0.23 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.23.1)\nRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.18.5)\nRequirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.16.0)\nRequirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\nRequirement already up-to-date: plotly in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (4.14.3)\nRequirement already satisfied, skipping upgrade: six in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from plotly) (1.15.0)\nRequirement already satisfied, skipping upgrade: retrying>=1.3.3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from plotly) (1.3.3)\nRequirement already up-to-date: chart-studio in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (1.1.0)\nRequirement already satisfied, skipping upgrade: plotly in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from chart-studio) (4.14.3)\nRequirement already satisfied, skipping upgrade: six in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from chart-studio) (1.15.0)\nRequirement already satisfied, skipping upgrade: retrying>=1.3.3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from chart-studio) (1.3.3)\nRequirement already satisfied, skipping upgrade: requests in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from chart-studio) (2.24.0)\nRequirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->chart-studio) (1.25.9)\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->chart-studio) (2020.12.5)\nRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->chart-studio) (3.0.4)\nRequirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->chart-studio) (2.9)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Import required libraries"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "import chart_studio.plotly as py\nimport plotly.graph_objs as go\nimport plotly as plotly\nimport pandas as pd\nimport numpy as np\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import SMOTENC\nfrom sklearn import metrics\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\n\nimport types\nimport pandas as pd\n\ndef __iter__(self): return 0\n\n\n",
            "execution_count": 3,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Import the data from GitHub."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Remove the data if you run this notebook more than once\n!rm equipment_failure_data_1.csv",
            "execution_count": 4,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#import first half from github\n!wget https://raw.githubusercontent.com/shadgriffin/machine_failure/master/equipment_failure_data_1.csv",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "--2021-02-17 23:23:17--  https://raw.githubusercontent.com/shadgriffin/machine_failure/master/equipment_failure_data_1.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 11219474 (11M) [text/plain]\nSaving to: \u2018equipment_failure_data_1.csv\u2019\n\nequipment_failure_d 100%[===================>]  10.70M  --.-KB/s    in 0.08s   \n\n2021-02-17 23:23:18 (127 MB/s) - \u2018equipment_failure_data_1.csv\u2019 saved [11219474/11219474]\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Convert csv to pandas dataframe\npd_data_1 = pd.read_csv(\"equipment_failure_data_1.csv\", sep=\",\", header=0)",
            "execution_count": 6,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Remove the data if you run this notebook more than once\n!rm equipment_failure_data_2.csv",
            "execution_count": 7,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Import the second half from github\n!wget https://raw.githubusercontent.com/shadgriffin/machine_failure/master/equipment_failure_data_2.csv",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "--2021-02-17 23:23:20--  https://raw.githubusercontent.com/shadgriffin/machine_failure/master/equipment_failure_data_2.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 11762512 (11M) [text/plain]\nSaving to: \u2018equipment_failure_data_2.csv\u2019\n\nequipment_failure_d 100%[===================>]  11.22M  --.-KB/s    in 0.1s    \n\n2021-02-17 23:23:20 (113 MB/s) - \u2018equipment_failure_data_2.csv\u2019 saved [11762512/11762512]\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# convert to pandas dataframe\npd_data_2 = pd.read_csv(\"equipment_failure_data_2.csv\", sep=\",\", header=0)",
            "execution_count": 9,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#concatenate the two data files into one dataframe\npd_data=pd.concat([pd_data_1, pd_data_2])\n\n",
            "execution_count": 10,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 2.0 Data Exporation <a id=\"explore\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_data.head()",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 11,
                    "data": {
                        "text/plain": "       ID     DATE REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  WELL_GROUP  \\\n0  100001  12/2/14              G                  O            Y           1   \n1  100001  12/3/14              G                  O            Y           1   \n2  100001  12/4/14              G                  O            Y           1   \n3  100001  12/5/14              G                  O            Y           1   \n4  100001  12/6/14              G                  O            Y           1   \n\n         S15         S17    S13      S5       S16  S19        S18  \\\n0  11.088000  145.223448  39.34  3501.0  8.426869  1.9  24.610345   \n1   8.877943  187.573214  39.20  3489.0  6.483714  1.9  24.671429   \n2   8.676444  148.363704  38.87  3459.0  6.159659  2.0  24.733333   \n3   9.988338  133.660000  39.47  3513.0  9.320308  2.0  24.773077   \n4   8.475264  197.181600  40.33  3589.0  8.022960  1.5  24.808000   \n\n   EQUIPMENT_FAILURE   S8  AGE_OF_EQUIPMENT  \n0                  0  0.0               880  \n1                  0  0.0               881  \n2                  0  0.0               882  \n3                  0  0.0               883  \n4                  0  0.0               884  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>DATE</th>\n      <th>REGION_CLUSTER</th>\n      <th>MAINTENANCE_VENDOR</th>\n      <th>MANUFACTURER</th>\n      <th>WELL_GROUP</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>S5</th>\n      <th>S16</th>\n      <th>S19</th>\n      <th>S18</th>\n      <th>EQUIPMENT_FAILURE</th>\n      <th>S8</th>\n      <th>AGE_OF_EQUIPMENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100001</td>\n      <td>12/2/14</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>11.088000</td>\n      <td>145.223448</td>\n      <td>39.34</td>\n      <td>3501.0</td>\n      <td>8.426869</td>\n      <td>1.9</td>\n      <td>24.610345</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>880</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100001</td>\n      <td>12/3/14</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.877943</td>\n      <td>187.573214</td>\n      <td>39.20</td>\n      <td>3489.0</td>\n      <td>6.483714</td>\n      <td>1.9</td>\n      <td>24.671429</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>881</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100001</td>\n      <td>12/4/14</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.676444</td>\n      <td>148.363704</td>\n      <td>38.87</td>\n      <td>3459.0</td>\n      <td>6.159659</td>\n      <td>2.0</td>\n      <td>24.733333</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>882</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100001</td>\n      <td>12/5/14</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>9.988338</td>\n      <td>133.660000</td>\n      <td>39.47</td>\n      <td>3513.0</td>\n      <td>9.320308</td>\n      <td>2.0</td>\n      <td>24.773077</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>883</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100001</td>\n      <td>12/6/14</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.475264</td>\n      <td>197.181600</td>\n      <td>40.33</td>\n      <td>3589.0</td>\n      <td>8.022960</td>\n      <td>1.5</td>\n      <td>24.808000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>884</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now that we have the data imported into a Jupiter Notebook, we can explore it. Here is metadata explaining all of the fields in the data set.\n\nID \u2014 ID field that represents a specific machine.\n\nDATE \u2014 The date of the observation.\n\nREGION_CLUSTER \u2014 a field that represents the region in which the machine resides.\n\nMAINTENANCE_VENDOR \u2014 a field that represents the company that provides maintenance and service to the machine.\n\nMANUFACTURER \u2014 the company that manufactured the equipment in question.\n\nWELL_GROUP \u2014 a field representing the type of machine.\n\nEQUIPMENT_AGE \u2014 Age of the machine, in days.\n\nS15 \u2014 A Sensor Value.\n\nS17 \u2014 A Sensor Value.\n\nS13 \u2014 A Sensor Value.\n\nS16 \u2014 A Sensor Value.\n\nS19 \u2014 A Sensor Value.\n\nS18 \u2014 A Sensor Value.\n\nS8 \u2014 A Sensor Value.\n\nEQUIPMENT_FAILURE \u2014 A \u20181\u2019 means that the equipment failed. A \u20180\u2019 means the equipment did not fail.\n\nOur first goal in this exercise is to build a model that predicts equipment failure. In other words, we will use the other variables in the data frame to predict EQUIPMENT_FAILURE.\n\nNow we will walk through the data.\n\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Examine the number of rows and columns.  The data has 307,751 rows and 16 columns."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\npd_data.shape",
            "execution_count": 12,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 12,
                    "data": {
                        "text/plain": "(307751, 16)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "There are 421 machines in the data set."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\nxxxx = pd.DataFrame(pd_data.groupby(['ID']).agg(['count']))\nxxxx.shape",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 13,
                    "data": {
                        "text/plain": "(421, 15)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "there are 731 unique dates in the data set."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\nxxxx = pd.DataFrame(pd_data.groupby(['DATE']).agg(['count']))\nxxxx.shape",
            "execution_count": 14,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 14,
                    "data": {
                        "text/plain": "(731, 15)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We have 731 unique dates.  So if we have 421 machines and 731 unique dates, we should have 307,751 total records.  Based on the .shape command, we have one record per machine per date value.  There are no duplicates in the data frame.\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "And to triple confirm, remove all duplicates and count the rows again."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_failure_thingy=pd_data\ndf_failure_thingy=df_failure_thingy.drop_duplicates(subset=['ID','DATE'])\ndf_failure_thingy.shape\n",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 15,
                    "data": {
                        "text/plain": "(307751, 16)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Look for null values in the fields -- There are none."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_data.isnull().sum(axis = 0)",
            "execution_count": 16,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 16,
                    "data": {
                        "text/plain": "ID                    0\nDATE                  0\nREGION_CLUSTER        0\nMAINTENANCE_VENDOR    0\nMANUFACTURER          0\nWELL_GROUP            0\nS15                   0\nS17                   0\nS13                   0\nS5                    0\nS16                   0\nS19                   0\nS18                   0\nEQUIPMENT_FAILURE     0\nS8                    0\nAGE_OF_EQUIPMENT      0\ndtype: int64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now let\u2019s examine the dependent variable in more detail. It appears that out of 307,751 records, we only have 421 failures. This corresponds to a failure rate of about .14%. In other words, for every failure, you have over 700 non-failures. This data set is very unbalanced. Later in this article, I will use a few techniques to mitigate the impact of a small number of observed failures."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xxxx = pd.DataFrame(pd_data.groupby(['EQUIPMENT_FAILURE'])['ID'].agg('count'))\nxxxx",
            "execution_count": 17,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 17,
                    "data": {
                        "text/plain": "                       ID\nEQUIPMENT_FAILURE        \n0                  307330\n1                     421",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n    </tr>\n    <tr>\n      <th>EQUIPMENT_FAILURE</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>307330</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>421</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We can also explore the data with descriptive statistics."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\npd_data.describe()",
            "execution_count": 18,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 18,
                    "data": {
                        "text/plain": "                  ID     WELL_GROUP            S15            S17  \\\ncount  307751.000000  307751.000000  307751.000000  307751.000000   \nmean   100310.826603       4.543943      14.585192      80.265541   \nstd       177.574390       2.284121       8.817056      85.804273   \nmin    100001.000000       1.000000       0.000000       0.000000   \n25%    100161.000000       3.000000       7.694100       0.000000   \n50%    100311.000000       5.000000      11.661600      31.680000   \n75%    100467.000000       6.000000      22.560000     160.080000   \nmax    100617.000000       8.000000      59.040000    2555.520000   \n\n                 S13             S5            S16            S19  \\\ncount  307751.000000  307751.000000  307751.000000  307751.000000   \nmean       35.018249    4675.848252       7.972097       9.069123   \nstd        14.446585    2521.074632       2.321949      16.898887   \nmin         0.000000       0.000000       0.000000       0.000000   \n25%        28.200000    3209.000000       6.621500       0.900000   \n50%        34.940000    4237.047619       8.004000       4.200000   \n75%        41.610000    5743.000000       9.460000      10.600000   \nmax       592.890000   52767.000000      24.600000     511.000000   \n\n                 S18  EQUIPMENT_FAILURE             S8  AGE_OF_EQUIPMENT  \ncount  307751.000000      307751.000000  307751.000000     307751.000000  \nmean      137.963064           0.001368     144.665715       2524.192399  \nstd       238.890128           0.036961     240.773926       3158.930976  \nmin         0.000000           0.000000     -16.490000          0.000000  \n25%        11.798276           0.000000       9.250000        721.000000  \n50%        38.200000           0.000000      53.080000       1113.000000  \n75%       150.900000           0.000000     165.092608       2784.000000  \nmax      4151.700000           1.000000    2068.110000      15170.000000  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>WELL_GROUP</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>S5</th>\n      <th>S16</th>\n      <th>S19</th>\n      <th>S18</th>\n      <th>EQUIPMENT_FAILURE</th>\n      <th>S8</th>\n      <th>AGE_OF_EQUIPMENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>307751.000000</td>\n      <td>307751.000000</td>\n      <td>307751.000000</td>\n      <td>307751.000000</td>\n      <td>307751.000000</td>\n      <td>307751.000000</td>\n      <td>307751.000000</td>\n      <td>307751.000000</td>\n      <td>307751.000000</td>\n      <td>307751.000000</td>\n      <td>307751.000000</td>\n      <td>307751.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>100310.826603</td>\n      <td>4.543943</td>\n      <td>14.585192</td>\n      <td>80.265541</td>\n      <td>35.018249</td>\n      <td>4675.848252</td>\n      <td>7.972097</td>\n      <td>9.069123</td>\n      <td>137.963064</td>\n      <td>0.001368</td>\n      <td>144.665715</td>\n      <td>2524.192399</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>177.574390</td>\n      <td>2.284121</td>\n      <td>8.817056</td>\n      <td>85.804273</td>\n      <td>14.446585</td>\n      <td>2521.074632</td>\n      <td>2.321949</td>\n      <td>16.898887</td>\n      <td>238.890128</td>\n      <td>0.036961</td>\n      <td>240.773926</td>\n      <td>3158.930976</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>100001.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-16.490000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>100161.000000</td>\n      <td>3.000000</td>\n      <td>7.694100</td>\n      <td>0.000000</td>\n      <td>28.200000</td>\n      <td>3209.000000</td>\n      <td>6.621500</td>\n      <td>0.900000</td>\n      <td>11.798276</td>\n      <td>0.000000</td>\n      <td>9.250000</td>\n      <td>721.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>100311.000000</td>\n      <td>5.000000</td>\n      <td>11.661600</td>\n      <td>31.680000</td>\n      <td>34.940000</td>\n      <td>4237.047619</td>\n      <td>8.004000</td>\n      <td>4.200000</td>\n      <td>38.200000</td>\n      <td>0.000000</td>\n      <td>53.080000</td>\n      <td>1113.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>100467.000000</td>\n      <td>6.000000</td>\n      <td>22.560000</td>\n      <td>160.080000</td>\n      <td>41.610000</td>\n      <td>5743.000000</td>\n      <td>9.460000</td>\n      <td>10.600000</td>\n      <td>150.900000</td>\n      <td>0.000000</td>\n      <td>165.092608</td>\n      <td>2784.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>100617.000000</td>\n      <td>8.000000</td>\n      <td>59.040000</td>\n      <td>2555.520000</td>\n      <td>592.890000</td>\n      <td>52767.000000</td>\n      <td>24.600000</td>\n      <td>511.000000</td>\n      <td>4151.700000</td>\n      <td>1.000000</td>\n      <td>2068.110000</td>\n      <td>15170.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Examine a simple correlation of the independent variable with the dependent variable.  "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xxx=pd_data.corr( method='pearson')\n\nxxx=xxx[['EQUIPMENT_FAILURE']]\nxxx['ABS_EQUIPMENT_FAILURE']=abs(xxx['EQUIPMENT_FAILURE'])\nxxx=xxx.sort_values(by=['ABS_EQUIPMENT_FAILURE'], ascending=[False])",
            "execution_count": 19,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "xxx",
            "execution_count": 20,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 20,
                    "data": {
                        "text/plain": "                   EQUIPMENT_FAILURE  ABS_EQUIPMENT_FAILURE\nEQUIPMENT_FAILURE       1.000000e+00           1.000000e+00\nS15                    -6.036352e-02           6.036352e-02\nS17                    -3.429070e-02           3.429070e-02\nS18                     9.765002e-03           9.765002e-03\nS13                    -8.617761e-03           8.617761e-03\nS5                     -7.189979e-03           7.189979e-03\nS8                      6.517148e-03           6.517148e-03\nS16                    -6.138895e-03           6.138895e-03\nS19                    -6.087474e-03           6.087474e-03\nAGE_OF_EQUIPMENT        4.733368e-04           4.733368e-04\nWELL_GROUP              7.048348e-17           7.048348e-17\nID                      2.959871e-18           2.959871e-18",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EQUIPMENT_FAILURE</th>\n      <th>ABS_EQUIPMENT_FAILURE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>EQUIPMENT_FAILURE</th>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>S15</th>\n      <td>-6.036352e-02</td>\n      <td>6.036352e-02</td>\n    </tr>\n    <tr>\n      <th>S17</th>\n      <td>-3.429070e-02</td>\n      <td>3.429070e-02</td>\n    </tr>\n    <tr>\n      <th>S18</th>\n      <td>9.765002e-03</td>\n      <td>9.765002e-03</td>\n    </tr>\n    <tr>\n      <th>S13</th>\n      <td>-8.617761e-03</td>\n      <td>8.617761e-03</td>\n    </tr>\n    <tr>\n      <th>S5</th>\n      <td>-7.189979e-03</td>\n      <td>7.189979e-03</td>\n    </tr>\n    <tr>\n      <th>S8</th>\n      <td>6.517148e-03</td>\n      <td>6.517148e-03</td>\n    </tr>\n    <tr>\n      <th>S16</th>\n      <td>-6.138895e-03</td>\n      <td>6.138895e-03</td>\n    </tr>\n    <tr>\n      <th>S19</th>\n      <td>-6.087474e-03</td>\n      <td>6.087474e-03</td>\n    </tr>\n    <tr>\n      <th>AGE_OF_EQUIPMENT</th>\n      <td>4.733368e-04</td>\n      <td>4.733368e-04</td>\n    </tr>\n    <tr>\n      <th>WELL_GROUP</th>\n      <td>7.048348e-17</td>\n      <td>7.048348e-17</td>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <td>2.959871e-18</td>\n      <td>2.959871e-18</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 3.0 Data transformations and Feature Engineering <a id=\"trans\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Next, we can transform our data for a machine learning model. Specifically, we will create running summaries of the sensor values. Running summaries of sensor values are often useful in predicting equipment failure. For example, if a temperature gauge indicates a machine is warmer than average for the last five days, it may mean something is wrong.\n\nRemember that we are working with a panel data set. That is, we have multiple machines measured over two years. As we create our running summaries, we have to make sure that our summaries do not include more than one machine. For example, if we create a ten-day moving average, we do not want the first nine days of a machine to have values from the previous machine.\n\nNote that I create twenty-one-day summaries in this example. This works for this use case, but it may be advantageous to use more or different time intervals for other situations.\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Convert dates from character to date."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "\n\npd_data['DATE'] = pd.to_datetime(pd_data['DATE'])\n\n\n\n",
            "execution_count": 21,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a new field called \u201cflipper\u201d that indicates when the id changes as the data are sorted by ID and DATE in ascending order. We will use this in a few other transformations."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_data=pd_data.sort_values(by=['ID','DATE'], ascending=[True, True])\n\npd_data['flipper'] = np.where((pd_data.ID != pd_data.ID.shift(1)), 1, 0)\npd_data.head()",
            "execution_count": 22,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 22,
                    "data": {
                        "text/plain": "       ID       DATE REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  \\\n0  100001 2014-12-02              G                  O            Y   \n1  100001 2014-12-03              G                  O            Y   \n2  100001 2014-12-04              G                  O            Y   \n3  100001 2014-12-05              G                  O            Y   \n4  100001 2014-12-06              G                  O            Y   \n\n   WELL_GROUP        S15         S17    S13      S5       S16  S19        S18  \\\n0           1  11.088000  145.223448  39.34  3501.0  8.426869  1.9  24.610345   \n1           1   8.877943  187.573214  39.20  3489.0  6.483714  1.9  24.671429   \n2           1   8.676444  148.363704  38.87  3459.0  6.159659  2.0  24.733333   \n3           1   9.988338  133.660000  39.47  3513.0  9.320308  2.0  24.773077   \n4           1   8.475264  197.181600  40.33  3589.0  8.022960  1.5  24.808000   \n\n   EQUIPMENT_FAILURE   S8  AGE_OF_EQUIPMENT  flipper  \n0                  0  0.0               880        1  \n1                  0  0.0               881        0  \n2                  0  0.0               882        0  \n3                  0  0.0               883        0  \n4                  0  0.0               884        0  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>DATE</th>\n      <th>REGION_CLUSTER</th>\n      <th>MAINTENANCE_VENDOR</th>\n      <th>MANUFACTURER</th>\n      <th>WELL_GROUP</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>S5</th>\n      <th>S16</th>\n      <th>S19</th>\n      <th>S18</th>\n      <th>EQUIPMENT_FAILURE</th>\n      <th>S8</th>\n      <th>AGE_OF_EQUIPMENT</th>\n      <th>flipper</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100001</td>\n      <td>2014-12-02</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>11.088000</td>\n      <td>145.223448</td>\n      <td>39.34</td>\n      <td>3501.0</td>\n      <td>8.426869</td>\n      <td>1.9</td>\n      <td>24.610345</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>880</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100001</td>\n      <td>2014-12-03</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.877943</td>\n      <td>187.573214</td>\n      <td>39.20</td>\n      <td>3489.0</td>\n      <td>6.483714</td>\n      <td>1.9</td>\n      <td>24.671429</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>881</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100001</td>\n      <td>2014-12-04</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.676444</td>\n      <td>148.363704</td>\n      <td>38.87</td>\n      <td>3459.0</td>\n      <td>6.159659</td>\n      <td>2.0</td>\n      <td>24.733333</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>882</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100001</td>\n      <td>2014-12-05</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>9.988338</td>\n      <td>133.660000</td>\n      <td>39.47</td>\n      <td>3513.0</td>\n      <td>9.320308</td>\n      <td>2.0</td>\n      <td>24.773077</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>883</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100001</td>\n      <td>2014-12-06</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.475264</td>\n      <td>197.181600</td>\n      <td>40.33</td>\n      <td>3589.0</td>\n      <td>8.022960</td>\n      <td>1.5</td>\n      <td>24.808000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>884</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Running summaries are often useful transformations for these types of problems.  For example, a running mean would be the average value over the last x days.  X, in this case, is the feature window.  The feature window is a parameter that depends on the context of the business problem.  I am setting the value to 21 days, but this may or may not work for your business problem."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#define your feature window. This is the window by which we will aggregate our sensor values.\nfeature_window=21",
            "execution_count": 23,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Calculate the number of days from the first day a machine appears to the current day. This field will be called \u201cTIME_SINCE_START\u201d Also, create a variable called \u201ctoo_soon.\u201d When \u201ctoo_soon\u201d is equal to 1, we have less than 21 days (feature_window) of history for the machine.\n\nWe will use these new variables to create a running mean, median, max, and min. \n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dfx=pd_data",
            "execution_count": 24,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Select the first record of each machine\n\nstarter=dfx[dfx['flipper'] == 1]\n\nstarter=starter[['DATE','ID']]",
            "execution_count": 25,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#rename date to start_date\nstarter=starter.rename(index=str, columns={\"DATE\": \"START_DATE\"})",
            "execution_count": 26,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#convert START_DATE to date\nstarter['START_DATE'] = pd.to_datetime(starter['START_DATE'])",
            "execution_count": 27,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Merge START_DATE to the original data set\n\ndfx=dfx.sort_values(by=['ID', 'DATE'], ascending=[True, True])\nstarter=starter.sort_values(by=['ID'], ascending=[True])\ndfx =dfx.merge(starter, on=['ID'], how='left')",
            "execution_count": 28,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# calculate the number of days since the beginning of each well. \ndfx['C'] = dfx['DATE'] - dfx['START_DATE']\ndfx['TIME_SINCE_START'] = dfx['C'] / np.timedelta64(1, 'D')\ndfx=dfx.drop(columns=['C'])\ndfx['too_soon'] = np.where((dfx.TIME_SINCE_START < feature_window) , 1, 0)",
            "execution_count": 29,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a running mean, max, min, and median for the sensor variables."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "dfx['S5_mean'] = np.where((dfx.too_soon == 0),(dfx['S5'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S5)\ndfx['S5_median'] = np.where((dfx.too_soon == 0),(dfx['S5'].rolling(min_periods=1, window=feature_window).median()) , dfx.S5)\ndfx['S5_max'] = np.where((dfx.too_soon == 0),(dfx['S5'].rolling(min_periods=1, window=feature_window).max()) , dfx.S5)\ndfx['S5_min'] = np.where((dfx.too_soon == 0),(dfx['S5'].rolling(min_periods=1, window=feature_window).min()) , dfx.S5)\n\n\ndfx['S13_mean'] = np.where((dfx.too_soon == 0),(dfx['S13'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S13)\ndfx['S13_median'] = np.where((dfx.too_soon == 0),(dfx['S13'].rolling(min_periods=1, window=feature_window).median()) , dfx.S13)\ndfx['S13_max'] = np.where((dfx.too_soon == 0),(dfx['S13'].rolling(min_periods=1, window=feature_window).max()) , dfx.S13)\ndfx['S13_min'] = np.where((dfx.too_soon == 0),(dfx['S13'].rolling(min_periods=1, window=feature_window).min()) , dfx.S13)\n\n\ndfx['S15_mean'] = np.where((dfx.too_soon == 0),(dfx['S15'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S15)\ndfx['S15_median'] = np.where((dfx.too_soon == 0),(dfx['S15'].rolling(min_periods=1, window=feature_window).median()) , dfx.S15)\ndfx['S15_max'] = np.where((dfx.too_soon == 0),(dfx['S15'].rolling(min_periods=1, window=feature_window).max()) , dfx.S15)\ndfx['S15_min'] = np.where((dfx.too_soon == 0),(dfx['S15'].rolling(min_periods=1, window=feature_window).min()) , dfx.S15)\n\ndfx['S16_mean'] = np.where((dfx.too_soon == 0),(dfx['S16'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S16)\ndfx['S16_median'] = np.where((dfx.too_soon == 0),(dfx['S16'].rolling(min_periods=1, window=feature_window).median()) , dfx.S16)\ndfx['S16_max'] = np.where((dfx.too_soon == 0),(dfx['S16'].rolling(min_periods=1, window=feature_window).max()) , dfx.S16)\ndfx['S16_min'] = np.where((dfx.too_soon == 0),(dfx['S16'].rolling(min_periods=1, window=feature_window).min()) , dfx.S16)\n\n\ndfx['S17_mean'] = np.where((dfx.too_soon == 0),(dfx['S17'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S17)\ndfx['S17_median'] = np.where((dfx.too_soon == 0),(dfx['S17'].rolling(min_periods=1, window=feature_window).median()) , dfx.S17)\ndfx['S17_max'] = np.where((dfx.too_soon == 0),(dfx['S17'].rolling(min_periods=1, window=feature_window).max()) , dfx.S17)\ndfx['S17_min'] = np.where((dfx.too_soon == 0),(dfx['S17'].rolling(min_periods=1, window=feature_window).min()) , dfx.S17)\n\ndfx['S18_mean'] = np.where((dfx.too_soon == 0),(dfx['S18'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S18)\ndfx['S18_median'] = np.where((dfx.too_soon == 0),(dfx['S18'].rolling(min_periods=1, window=feature_window).median()) , dfx.S18)\ndfx['S18_max'] = np.where((dfx.too_soon == 0),(dfx['S18'].rolling(min_periods=1, window=feature_window).max()) , dfx.S18)\ndfx['S18_min'] = np.where((dfx.too_soon == 0),(dfx['S18'].rolling(min_periods=1, window=feature_window).min()) , dfx.S18)\n\n\n\ndfx['S19_mean'] = np.where((dfx.too_soon == 0),(dfx['S19'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S19)\ndfx['S19_median'] = np.where((dfx.too_soon == 0),(dfx['S19'].rolling(min_periods=1, window=feature_window).median()) , dfx.S19)\ndfx['S19_max'] = np.where((dfx.too_soon == 0),(dfx['S19'].rolling(min_periods=1, window=feature_window).max()) , dfx.S19)\ndfx['S19_min'] = np.where((dfx.too_soon == 0),(dfx['S19'].rolling(min_periods=1, window=feature_window).min()) , dfx.S19)\n\n\ndfx.head()",
            "execution_count": 30,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 30,
                    "data": {
                        "text/plain": "       ID       DATE REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  \\\n0  100001 2014-12-02              G                  O            Y   \n1  100001 2014-12-03              G                  O            Y   \n2  100001 2014-12-04              G                  O            Y   \n3  100001 2014-12-05              G                  O            Y   \n4  100001 2014-12-06              G                  O            Y   \n\n   WELL_GROUP        S15         S17    S13      S5  ...     S17_max  \\\n0           1  11.088000  145.223448  39.34  3501.0  ...  145.223448   \n1           1   8.877943  187.573214  39.20  3489.0  ...  187.573214   \n2           1   8.676444  148.363704  38.87  3459.0  ...  148.363704   \n3           1   9.988338  133.660000  39.47  3513.0  ...  133.660000   \n4           1   8.475264  197.181600  40.33  3589.0  ...  197.181600   \n\n      S17_min   S18_mean  S18_median    S18_max    S18_min  S19_mean  \\\n0  145.223448  24.610345   24.610345  24.610345  24.610345       1.9   \n1  187.573214  24.671429   24.671429  24.671429  24.671429       1.9   \n2  148.363704  24.733333   24.733333  24.733333  24.733333       2.0   \n3  133.660000  24.773077   24.773077  24.773077  24.773077       2.0   \n4  197.181600  24.808000   24.808000  24.808000  24.808000       1.5   \n\n  S19_median  S19_max  S19_min  \n0        1.9      1.9      1.9  \n1        1.9      1.9      1.9  \n2        2.0      2.0      2.0  \n3        2.0      2.0      2.0  \n4        1.5      1.5      1.5  \n\n[5 rows x 48 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>DATE</th>\n      <th>REGION_CLUSTER</th>\n      <th>MAINTENANCE_VENDOR</th>\n      <th>MANUFACTURER</th>\n      <th>WELL_GROUP</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>S5</th>\n      <th>...</th>\n      <th>S17_max</th>\n      <th>S17_min</th>\n      <th>S18_mean</th>\n      <th>S18_median</th>\n      <th>S18_max</th>\n      <th>S18_min</th>\n      <th>S19_mean</th>\n      <th>S19_median</th>\n      <th>S19_max</th>\n      <th>S19_min</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100001</td>\n      <td>2014-12-02</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>11.088000</td>\n      <td>145.223448</td>\n      <td>39.34</td>\n      <td>3501.0</td>\n      <td>...</td>\n      <td>145.223448</td>\n      <td>145.223448</td>\n      <td>24.610345</td>\n      <td>24.610345</td>\n      <td>24.610345</td>\n      <td>24.610345</td>\n      <td>1.9</td>\n      <td>1.9</td>\n      <td>1.9</td>\n      <td>1.9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100001</td>\n      <td>2014-12-03</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.877943</td>\n      <td>187.573214</td>\n      <td>39.20</td>\n      <td>3489.0</td>\n      <td>...</td>\n      <td>187.573214</td>\n      <td>187.573214</td>\n      <td>24.671429</td>\n      <td>24.671429</td>\n      <td>24.671429</td>\n      <td>24.671429</td>\n      <td>1.9</td>\n      <td>1.9</td>\n      <td>1.9</td>\n      <td>1.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100001</td>\n      <td>2014-12-04</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.676444</td>\n      <td>148.363704</td>\n      <td>38.87</td>\n      <td>3459.0</td>\n      <td>...</td>\n      <td>148.363704</td>\n      <td>148.363704</td>\n      <td>24.733333</td>\n      <td>24.733333</td>\n      <td>24.733333</td>\n      <td>24.733333</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100001</td>\n      <td>2014-12-05</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>9.988338</td>\n      <td>133.660000</td>\n      <td>39.47</td>\n      <td>3513.0</td>\n      <td>...</td>\n      <td>133.660000</td>\n      <td>133.660000</td>\n      <td>24.773077</td>\n      <td>24.773077</td>\n      <td>24.773077</td>\n      <td>24.773077</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100001</td>\n      <td>2014-12-06</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.475264</td>\n      <td>197.181600</td>\n      <td>40.33</td>\n      <td>3589.0</td>\n      <td>...</td>\n      <td>197.181600</td>\n      <td>197.181600</td>\n      <td>24.808000</td>\n      <td>24.808000</td>\n      <td>24.808000</td>\n      <td>24.808000</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>1.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 48 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Another useful transformation is to look for sudden spikes in sensor values. This code creates a value indicating how far the current value is from the immediate norm."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "dfx['S5_chg'] = np.where((dfx.S5_mean == 0),0 , dfx.S5/dfx.S5_mean)\n\n\ndfx['S13_chg'] = np.where((dfx.S13_mean == 0),0 , dfx.S13/dfx.S13_mean)\n\ndfx['S15_chg'] = np.where((dfx.S15_mean==0),0 , dfx.S15/dfx.S15_mean)\ndfx['S16_chg'] = np.where((dfx.S16_mean == 0),0 , dfx.S16/dfx.S16_mean)\ndfx['S17_chg'] = np.where((dfx.S17_mean == 0),0 , dfx.S17/dfx.S17_mean)\ndfx['S18_chg'] = np.where((dfx.S18_mean == 0),0 , dfx.S18/dfx.S18_mean)\ndfx['S19_chg'] = np.where((dfx.S19_mean == 0),0 , dfx.S19/dfx.S19_mean)",
            "execution_count": 31,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#copy the data set to the original name\npd_data=dfx",
            "execution_count": 32,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 4.0 Dealing with the small number of failures. <a id=\"small\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 4.1 Expand the Failure (Target) Window <a id=\"window\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Machines are engineered to last. If something breaks all the time, you won\u2019t buy it, would you?\n\nBecause machines generally last a long time, we typically do not have many examples of failure. This means the data sets we use in PM are almost always unbalanced. \n\nOne way to increase the number of failures is to expand the failure or target window. That is, make the dependent variable, not just the day the equipment failed but the 28 days (or another appropriate interval) leading up to the failure.\n\nIn this example, I use a 28-day target window. We will use the 28 days leading up to a failure as the dependent variable in our model.\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "target_window=28",
            "execution_count": 33,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Sort the data and reset the index."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_data=pd_data.sort_values(by=['ID', 'DATE'], ascending=[True, True])\npd_data.reset_index(level=0, inplace=True)",
            "execution_count": 34,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a new data frame that contains the failure records.  Rename DATE to FAILURE_DATE"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "\n\ndf_failure_thingy=pd_data[pd_data['EQUIPMENT_FAILURE'] == 1]\n\ndf_failure_thingy=df_failure_thingy[['DATE','ID']]\n\ndf_failure_thingy=df_failure_thingy.rename(index=str, columns={\"DATE\": \"FAILURE_DATE\"})\n\npd_data=pd_data.sort_values(by=['ID'], ascending=[True])\ndf_failure_thingy=df_failure_thingy.sort_values(by=['ID'], ascending=[True])\n",
            "execution_count": 35,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Append the FAILURE_DATE to each ID."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "\n\npd_data =pd_data.merge(df_failure_thingy, on=['ID'], how='left')",
            "execution_count": 36,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "For each record, calculate the number of days until failure."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "\n\npd_data=pd_data.sort_values(by=['ID','DATE'], ascending=[True, True])\n\npd_data['FAILURE_DATE'] = pd.to_datetime(pd_data['FAILURE_DATE'])\npd_data['DATE'] = pd.to_datetime(pd_data['DATE'])\npd_data['C'] = pd_data['FAILURE_DATE'] - pd_data['DATE']\n\npd_data['TIME_TO_FAILURE'] = pd_data['C'] / np.timedelta64(1, 'D')",
            "execution_count": 37,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Clean up and sort the records by ID and DATE"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_data=pd_data.drop(columns=['index'])",
            "execution_count": 38,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_data=pd_data.sort_values(by=['ID', 'DATE'], ascending=[True, True])\n\n",
            "execution_count": 39,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_data.reset_index(inplace=True)\n",
            "execution_count": 40,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_data.head()",
            "execution_count": 41,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 41,
                    "data": {
                        "text/plain": "   index      ID       DATE REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  \\\n0      0  100001 2014-12-02              G                  O            Y   \n1    549  100001 2014-12-03              G                  O            Y   \n2    483  100001 2014-12-04              G                  O            Y   \n3    484  100001 2014-12-05              G                  O            Y   \n4    485  100001 2014-12-06              G                  O            Y   \n\n   WELL_GROUP        S15         S17    S13  ...  S5_chg  S13_chg  S15_chg  \\\n0           1  11.088000  145.223448  39.34  ...     1.0      1.0      1.0   \n1           1   8.877943  187.573214  39.20  ...     1.0      1.0      1.0   \n2           1   8.676444  148.363704  38.87  ...     1.0      1.0      1.0   \n3           1   9.988338  133.660000  39.47  ...     1.0      1.0      1.0   \n4           1   8.475264  197.181600  40.33  ...     1.0      1.0      1.0   \n\n   S16_chg  S17_chg  S18_chg  S19_chg  FAILURE_DATE        C  TIME_TO_FAILURE  \n0      1.0      1.0      1.0      1.0    2015-04-24 143 days            143.0  \n1      1.0      1.0      1.0      1.0    2015-04-24 142 days            142.0  \n2      1.0      1.0      1.0      1.0    2015-04-24 141 days            141.0  \n3      1.0      1.0      1.0      1.0    2015-04-24 140 days            140.0  \n4      1.0      1.0      1.0      1.0    2015-04-24 139 days            139.0  \n\n[5 rows x 59 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>ID</th>\n      <th>DATE</th>\n      <th>REGION_CLUSTER</th>\n      <th>MAINTENANCE_VENDOR</th>\n      <th>MANUFACTURER</th>\n      <th>WELL_GROUP</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>...</th>\n      <th>S5_chg</th>\n      <th>S13_chg</th>\n      <th>S15_chg</th>\n      <th>S16_chg</th>\n      <th>S17_chg</th>\n      <th>S18_chg</th>\n      <th>S19_chg</th>\n      <th>FAILURE_DATE</th>\n      <th>C</th>\n      <th>TIME_TO_FAILURE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>100001</td>\n      <td>2014-12-02</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>11.088000</td>\n      <td>145.223448</td>\n      <td>39.34</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2015-04-24</td>\n      <td>143 days</td>\n      <td>143.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549</td>\n      <td>100001</td>\n      <td>2014-12-03</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.877943</td>\n      <td>187.573214</td>\n      <td>39.20</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2015-04-24</td>\n      <td>142 days</td>\n      <td>142.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>483</td>\n      <td>100001</td>\n      <td>2014-12-04</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.676444</td>\n      <td>148.363704</td>\n      <td>38.87</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2015-04-24</td>\n      <td>141 days</td>\n      <td>141.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>484</td>\n      <td>100001</td>\n      <td>2014-12-05</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>9.988338</td>\n      <td>133.660000</td>\n      <td>39.47</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2015-04-24</td>\n      <td>140 days</td>\n      <td>140.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>485</td>\n      <td>100001</td>\n      <td>2014-12-06</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.475264</td>\n      <td>197.181600</td>\n      <td>40.33</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2015-04-24</td>\n      <td>139 days</td>\n      <td>139.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 59 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a new variable, FAILURE_TARGET.  It is equal to 1 if the record proceeds a failure by \"failure_window\" days or less."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_data['FAILURE_TARGET'] = np.where(((pd_data.TIME_TO_FAILURE < target_window) & ((pd_data.TIME_TO_FAILURE>=0))), 1, 0)\n\npd_data.head()",
            "execution_count": 42,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 42,
                    "data": {
                        "text/plain": "   index      ID       DATE REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  \\\n0      0  100001 2014-12-02              G                  O            Y   \n1    549  100001 2014-12-03              G                  O            Y   \n2    483  100001 2014-12-04              G                  O            Y   \n3    484  100001 2014-12-05              G                  O            Y   \n4    485  100001 2014-12-06              G                  O            Y   \n\n   WELL_GROUP        S15         S17    S13  ...  S13_chg  S15_chg  S16_chg  \\\n0           1  11.088000  145.223448  39.34  ...      1.0      1.0      1.0   \n1           1   8.877943  187.573214  39.20  ...      1.0      1.0      1.0   \n2           1   8.676444  148.363704  38.87  ...      1.0      1.0      1.0   \n3           1   9.988338  133.660000  39.47  ...      1.0      1.0      1.0   \n4           1   8.475264  197.181600  40.33  ...      1.0      1.0      1.0   \n\n   S17_chg  S18_chg  S19_chg  FAILURE_DATE        C TIME_TO_FAILURE  \\\n0      1.0      1.0      1.0    2015-04-24 143 days           143.0   \n1      1.0      1.0      1.0    2015-04-24 142 days           142.0   \n2      1.0      1.0      1.0    2015-04-24 141 days           141.0   \n3      1.0      1.0      1.0    2015-04-24 140 days           140.0   \n4      1.0      1.0      1.0    2015-04-24 139 days           139.0   \n\n   FAILURE_TARGET  \n0               0  \n1               0  \n2               0  \n3               0  \n4               0  \n\n[5 rows x 60 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>ID</th>\n      <th>DATE</th>\n      <th>REGION_CLUSTER</th>\n      <th>MAINTENANCE_VENDOR</th>\n      <th>MANUFACTURER</th>\n      <th>WELL_GROUP</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>...</th>\n      <th>S13_chg</th>\n      <th>S15_chg</th>\n      <th>S16_chg</th>\n      <th>S17_chg</th>\n      <th>S18_chg</th>\n      <th>S19_chg</th>\n      <th>FAILURE_DATE</th>\n      <th>C</th>\n      <th>TIME_TO_FAILURE</th>\n      <th>FAILURE_TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>100001</td>\n      <td>2014-12-02</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>11.088000</td>\n      <td>145.223448</td>\n      <td>39.34</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2015-04-24</td>\n      <td>143 days</td>\n      <td>143.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549</td>\n      <td>100001</td>\n      <td>2014-12-03</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.877943</td>\n      <td>187.573214</td>\n      <td>39.20</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2015-04-24</td>\n      <td>142 days</td>\n      <td>142.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>483</td>\n      <td>100001</td>\n      <td>2014-12-04</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.676444</td>\n      <td>148.363704</td>\n      <td>38.87</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2015-04-24</td>\n      <td>141 days</td>\n      <td>141.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>484</td>\n      <td>100001</td>\n      <td>2014-12-05</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>9.988338</td>\n      <td>133.660000</td>\n      <td>39.47</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2015-04-24</td>\n      <td>140 days</td>\n      <td>140.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>485</td>\n      <td>100001</td>\n      <td>2014-12-06</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.475264</td>\n      <td>197.181600</td>\n      <td>40.33</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2015-04-24</td>\n      <td>139 days</td>\n      <td>139.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 60 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "tips_summed = pd_data.groupby(['FAILURE_TARGET'])['S5'].count()\ntips_summed",
            "execution_count": 43,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 43,
                    "data": {
                        "text/plain": "FAILURE_TARGET\n0    296011\n1     11740\nName: S5, dtype: int64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The new field occurs about 4% of the time."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_data['FAILURE_TARGET'].mean()",
            "execution_count": 44,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 44,
                    "data": {
                        "text/plain": "0.03814772332177637"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now we have 11,740 target observations. This is better, but the data set is far from balanced. In the next section, we will use SMOTE to increase the number of failures synthetically. However, let\u2019s split our data into training, testing, and a validation sample before we do that."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 4.2 Create the Testing, Training and Validation Groupings <a id=\"groups\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Because we are dealing with a panel data set (cross-sectional time-series), it is better not to take a random sample of all records. Doing so would put the records from one machine in all three sample data sets. To avoid this, we\u2019ll randomly select IDs and place all of the records for each machine in either the training, testing, or validation data set."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "#Get a Unique List of All IDs \n\n\naa=pd_data\n\npd_id=aa.drop_duplicates(subset='ID')\npd_id=pd_id[['ID']]\npd_id.shape\n",
            "execution_count": 45,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 45,
                    "data": {
                        "text/plain": "(421, 1)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a new variable with a random number between 0 and 1"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "np.random.seed(42)",
            "execution_count": 46,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_id['wookie'] = (np.random.randint(0, 10000, pd_id.shape[0]))/10000",
            "execution_count": 47,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "\npd_id=pd_id[['ID', 'wookie']]",
            "execution_count": 48,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Give each record a 30% chance of being in the validation, a 35% chance of being in the testing, and a 35% chance of being in the training data set.\n"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_id['MODELING_GROUP'] = np.where(((pd_id.wookie <= 0.35)), 'TRAINING', np.where(((pd_id.wookie <= 0.65)), 'VALIDATION', 'TESTING'))",
            "execution_count": 49,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This is how many machines fall in each group."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "tips_summed = pd_id.groupby(['MODELING_GROUP'])['wookie'].count()\ntips_summed",
            "execution_count": 50,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 50,
                    "data": {
                        "text/plain": "MODELING_GROUP\nTESTING       149\nTRAINING      146\nVALIDATION    126\nName: wookie, dtype: int64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Append the Group of each id to each individual record."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_data=pd_data.sort_values(by=['ID'], ascending=[True])\npd_id=pd_id.sort_values(by=['ID'], ascending=[True])",
            "execution_count": 51,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_data =pd_data.merge(pd_id, on=['ID'], how='inner')\n\npd_data.head()",
            "execution_count": 52,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 52,
                    "data": {
                        "text/plain": "   index      ID       DATE REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  \\\n0      0  100001 2014-12-02              G                  O            Y   \n1      1  100001 2016-03-29              G                  O            Y   \n2      2  100001 2016-03-30              G                  O            Y   \n3      3  100001 2016-03-31              G                  O            Y   \n4      4  100001 2016-04-01              G                  O            Y   \n\n   WELL_GROUP     S15         S17    S13  ...   S16_chg  S17_chg   S18_chg  \\\n0           1  11.088  145.223448  39.34  ...  1.000000      1.0  1.000000   \n1           1  18.960    0.000000  38.87  ...  1.080334      0.0  0.909801   \n2           1  29.040    0.000000  37.36  ...  1.093691      0.0  0.906040   \n3           1  18.000    0.000000  38.81  ...  0.910905      0.0  0.919466   \n4           1  26.160    0.000000  39.47  ...  1.160104      0.0  0.932363   \n\n    S19_chg  FAILURE_DATE         C  TIME_TO_FAILURE  FAILURE_TARGET wookie  \\\n0  1.000000    2015-04-24  143 days            143.0               0  0.727   \n1  0.613483    2015-04-24 -340 days           -340.0               0  0.727   \n2  0.677419    2015-04-24 -341 days           -341.0               0  0.727   \n3  0.695035    2015-04-24 -342 days           -342.0               0  0.727   \n4  0.690141    2015-04-24 -343 days           -343.0               0  0.727   \n\n   MODELING_GROUP  \n0         TESTING  \n1         TESTING  \n2         TESTING  \n3         TESTING  \n4         TESTING  \n\n[5 rows x 62 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>ID</th>\n      <th>DATE</th>\n      <th>REGION_CLUSTER</th>\n      <th>MAINTENANCE_VENDOR</th>\n      <th>MANUFACTURER</th>\n      <th>WELL_GROUP</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>...</th>\n      <th>S16_chg</th>\n      <th>S17_chg</th>\n      <th>S18_chg</th>\n      <th>S19_chg</th>\n      <th>FAILURE_DATE</th>\n      <th>C</th>\n      <th>TIME_TO_FAILURE</th>\n      <th>FAILURE_TARGET</th>\n      <th>wookie</th>\n      <th>MODELING_GROUP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>100001</td>\n      <td>2014-12-02</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>11.088</td>\n      <td>145.223448</td>\n      <td>39.34</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2015-04-24</td>\n      <td>143 days</td>\n      <td>143.0</td>\n      <td>0</td>\n      <td>0.727</td>\n      <td>TESTING</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>100001</td>\n      <td>2016-03-29</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>18.960</td>\n      <td>0.000000</td>\n      <td>38.87</td>\n      <td>...</td>\n      <td>1.080334</td>\n      <td>0.0</td>\n      <td>0.909801</td>\n      <td>0.613483</td>\n      <td>2015-04-24</td>\n      <td>-340 days</td>\n      <td>-340.0</td>\n      <td>0</td>\n      <td>0.727</td>\n      <td>TESTING</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>100001</td>\n      <td>2016-03-30</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>29.040</td>\n      <td>0.000000</td>\n      <td>37.36</td>\n      <td>...</td>\n      <td>1.093691</td>\n      <td>0.0</td>\n      <td>0.906040</td>\n      <td>0.677419</td>\n      <td>2015-04-24</td>\n      <td>-341 days</td>\n      <td>-341.0</td>\n      <td>0</td>\n      <td>0.727</td>\n      <td>TESTING</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>100001</td>\n      <td>2016-03-31</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>18.000</td>\n      <td>0.000000</td>\n      <td>38.81</td>\n      <td>...</td>\n      <td>0.910905</td>\n      <td>0.0</td>\n      <td>0.919466</td>\n      <td>0.695035</td>\n      <td>2015-04-24</td>\n      <td>-342 days</td>\n      <td>-342.0</td>\n      <td>0</td>\n      <td>0.727</td>\n      <td>TESTING</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>100001</td>\n      <td>2016-04-01</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>26.160</td>\n      <td>0.000000</td>\n      <td>39.47</td>\n      <td>...</td>\n      <td>1.160104</td>\n      <td>0.0</td>\n      <td>0.932363</td>\n      <td>0.690141</td>\n      <td>2015-04-24</td>\n      <td>-343 days</td>\n      <td>-343.0</td>\n      <td>0</td>\n      <td>0.727</td>\n      <td>TESTING</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 62 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This is how many records are in each group."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "tips_summed = pd_data.groupby(['MODELING_GROUP'])['wookie'].count()\ntips_summed",
            "execution_count": 53,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 53,
                    "data": {
                        "text/plain": "MODELING_GROUP\nTESTING       108919\nTRAINING      106726\nVALIDATION     92106\nName: wookie, dtype: int64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This is how many failure targets are in each group."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "tips_summed = pd_data.groupby(['MODELING_GROUP'])['FAILURE_TARGET'].sum()\ntips_summed",
            "execution_count": 54,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 54,
                    "data": {
                        "text/plain": "MODELING_GROUP\nTESTING       4151\nTRAINING      4071\nVALIDATION    3518\nName: FAILURE_TARGET, dtype: int64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a separate data frame for the training data.  We will use this data set to build the model."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_training=pd_data[pd_data['MODELING_GROUP'] == 'TRAINING']\ndf_training=df_training.drop(columns=['MODELING_GROUP','C','wookie','TIME_TO_FAILURE','flipper','START_DATE'])\ndf_training.shape",
            "execution_count": 55,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 55,
                    "data": {
                        "text/plain": "(106726, 56)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a separate data frame for the training and testing data sets.  We will use this to tweak our modeling results."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "df_train_test=pd_data[pd_data['MODELING_GROUP'] != 'VALIDATION']\n\ndf_train_test=df_train_test.drop(columns=['wookie','TIME_TO_FAILURE','flipper','START_DATE'])\ndf_train_test.shape",
            "execution_count": 56,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 56,
                    "data": {
                        "text/plain": "(215645, 58)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a separate data frame for all the data. We will use this to validate the model and compare the accuracy of all groups."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_total=pd_data.drop(columns=['C','wookie','TIME_TO_FAILURE','flipper','START_DATE'])\ndf_total.shape",
            "execution_count": 57,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 57,
                    "data": {
                        "text/plain": "(307751, 57)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 4.3 SMOTE the Training Data <a id=\"smote\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Note that we are only balancing the training data set. You may be asking why. Remember that our goal is to build a model the represents reality, right? When we SMOTE the data, we change the failure rate to 50%. This is nowhere near what we see in the actual machine data.  Thus, it makes sense to build the model on the SMOTE data but evaluate it on the unaltered data. The unaltered data will be a better reflection of what to expect when you deploy the model to production.\n\nDefine the Training features and Target."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "training_features=df_training[['REGION_CLUSTER','MAINTENANCE_VENDOR','MANUFACTURER','WELL_GROUP','AGE_OF_EQUIPMENT','S15','S17','S13','S5',\n 'S16','S19','S18','S8','S5_mean','S5_median','S5_max','S5_min','S13_mean','S13_median','S13_max','S13_min','S15_mean','S15_median',\n 'S15_max','S15_min','S16_mean','S16_median','S16_max','S16_min','S17_mean','S17_median','S17_max','S17_min','S18_mean','S18_median','S18_max','S18_min','S19_mean','S19_median','S19_max','S19_min',\n 'S5_chg','S13_chg','S15_chg','S16_chg','S17_chg','S18_chg','S19_chg']]",
            "execution_count": 58,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "training_target=df_training[['FAILURE_TARGET']]",
            "execution_count": 59,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Synthetically Balance the training data sets with a SMOTE algorithm. After we apply the SMOTE algorithm, we will have a balanced data set. 50% Failures and 50% Non-Failures. Note that this takes a while to run."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#uncomment these options if you want to expand the number of rows and columns that appear visually on the screen.\n\n#pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', None)",
            "execution_count": 60,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import SMOTENC\nsmx = SMOTENC(random_state=12,  categorical_features=[0, 1, 2, 3])",
            "execution_count": 61,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "x_res, y_res = smx.fit_sample(training_features, training_target.values.ravel())",
            "execution_count": 62,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Convert the SMOTE output back to complete data frames with independent and dependent variables.  Examine the results."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Format the Independent Variables."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_x=pd.DataFrame(x_res)\n\ndf_x.columns = [\n 'REGION_CLUSTER','MAINTENANCE_VENDOR','MANUFACTURER','WELL_GROUP','AGE_OF_EQUIPMENT','S15','S17','S13','S5','S16','S19',\n 'S18','S8','S5_mean','S5_median','S5_max','S5_min','S13_mean','S13_median','S13_max','S13_min','S15_mean','S15_median','S15_max',\n 'S15_min','S16_mean','S16_median','S16_max','S16_min','S17_mean','S17_median','S17_max','S17_min','S18_mean','S18_median','S18_max','S18_min',\n 'S19_mean','S19_median','S19_max','S19_min','S5_chg','S13_chg','S15_chg','S16_chg','S17_chg','S18_chg','S19_chg']\ndf_x.head()",
            "execution_count": 63,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 63,
                    "data": {
                        "text/plain": "  REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  WELL_GROUP  \\\n0              D                  L            R           6   \n1              D                  L            R           6   \n2              D                  L            R           6   \n3              D                  L            R           6   \n4              D                  L            R           6   \n\n   AGE_OF_EQUIPMENT      S15     S17    S13      S5     S16  ...  S19_median  \\\n0              1308  15.5184  188.10  36.29  4318.0  8.0073  ...        22.4   \n1              1307  10.3032  149.24  36.78  4377.0  7.0766  ...        22.4   \n2              1306  11.4480  187.45  35.84  4265.0  8.0259  ...        22.4   \n3              1302  15.1368  148.33  37.53  4466.0  8.7163  ...        22.4   \n4              1304  14.3736  179.30  36.31  4321.0  7.9396  ...        22.4   \n\n   S19_max  S19_min    S5_chg   S13_chg   S15_chg   S16_chg   S17_chg  \\\n0     28.9     22.4  0.989654  0.989779  1.208706  0.913224  1.150727   \n1     28.9     22.4  1.001165  1.001141  0.800762  0.799231  0.931453   \n2     28.9     22.4  0.974444  0.974443  0.886546  0.906484  1.158515   \n3     28.9     22.4  1.015319  1.015344  1.168344  0.992329  0.922866   \n4     28.9     22.4  0.983099  0.983085  1.094500  0.902220  1.132530   \n\n    S18_chg   S19_chg  \n0  0.995684  0.911805  \n1  0.991996  0.911805  \n2  0.985806  0.911805  \n3  0.973863  0.911805  \n4  0.980886  0.911805  \n\n[5 rows x 48 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>REGION_CLUSTER</th>\n      <th>MAINTENANCE_VENDOR</th>\n      <th>MANUFACTURER</th>\n      <th>WELL_GROUP</th>\n      <th>AGE_OF_EQUIPMENT</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>S5</th>\n      <th>S16</th>\n      <th>...</th>\n      <th>S19_median</th>\n      <th>S19_max</th>\n      <th>S19_min</th>\n      <th>S5_chg</th>\n      <th>S13_chg</th>\n      <th>S15_chg</th>\n      <th>S16_chg</th>\n      <th>S17_chg</th>\n      <th>S18_chg</th>\n      <th>S19_chg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>D</td>\n      <td>L</td>\n      <td>R</td>\n      <td>6</td>\n      <td>1308</td>\n      <td>15.5184</td>\n      <td>188.10</td>\n      <td>36.29</td>\n      <td>4318.0</td>\n      <td>8.0073</td>\n      <td>...</td>\n      <td>22.4</td>\n      <td>28.9</td>\n      <td>22.4</td>\n      <td>0.989654</td>\n      <td>0.989779</td>\n      <td>1.208706</td>\n      <td>0.913224</td>\n      <td>1.150727</td>\n      <td>0.995684</td>\n      <td>0.911805</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D</td>\n      <td>L</td>\n      <td>R</td>\n      <td>6</td>\n      <td>1307</td>\n      <td>10.3032</td>\n      <td>149.24</td>\n      <td>36.78</td>\n      <td>4377.0</td>\n      <td>7.0766</td>\n      <td>...</td>\n      <td>22.4</td>\n      <td>28.9</td>\n      <td>22.4</td>\n      <td>1.001165</td>\n      <td>1.001141</td>\n      <td>0.800762</td>\n      <td>0.799231</td>\n      <td>0.931453</td>\n      <td>0.991996</td>\n      <td>0.911805</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>D</td>\n      <td>L</td>\n      <td>R</td>\n      <td>6</td>\n      <td>1306</td>\n      <td>11.4480</td>\n      <td>187.45</td>\n      <td>35.84</td>\n      <td>4265.0</td>\n      <td>8.0259</td>\n      <td>...</td>\n      <td>22.4</td>\n      <td>28.9</td>\n      <td>22.4</td>\n      <td>0.974444</td>\n      <td>0.974443</td>\n      <td>0.886546</td>\n      <td>0.906484</td>\n      <td>1.158515</td>\n      <td>0.985806</td>\n      <td>0.911805</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>D</td>\n      <td>L</td>\n      <td>R</td>\n      <td>6</td>\n      <td>1302</td>\n      <td>15.1368</td>\n      <td>148.33</td>\n      <td>37.53</td>\n      <td>4466.0</td>\n      <td>8.7163</td>\n      <td>...</td>\n      <td>22.4</td>\n      <td>28.9</td>\n      <td>22.4</td>\n      <td>1.015319</td>\n      <td>1.015344</td>\n      <td>1.168344</td>\n      <td>0.992329</td>\n      <td>0.922866</td>\n      <td>0.973863</td>\n      <td>0.911805</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>D</td>\n      <td>L</td>\n      <td>R</td>\n      <td>6</td>\n      <td>1304</td>\n      <td>14.3736</td>\n      <td>179.30</td>\n      <td>36.31</td>\n      <td>4321.0</td>\n      <td>7.9396</td>\n      <td>...</td>\n      <td>22.4</td>\n      <td>28.9</td>\n      <td>22.4</td>\n      <td>0.983099</td>\n      <td>0.983085</td>\n      <td>1.094500</td>\n      <td>0.902220</td>\n      <td>1.132530</td>\n      <td>0.980886</td>\n      <td>0.911805</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 48 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Format the Dependent Variable."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_y=pd.DataFrame(y_res)\ndf_y.columns = ['FAILURE_TARGET']",
            "execution_count": 64,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Check that the dependent variable is balanced.  It is."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_y.mean(axis = 0) ",
            "execution_count": 65,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 65,
                    "data": {
                        "text/plain": "FAILURE_TARGET    0.5\ndtype: float64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "markdown",
            "source": "Merge the dependent and independent variables post SMOTE into a data frame."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_balanced = pd.concat([df_y, df_x], axis=1)\ndf_balanced.head()",
            "execution_count": 66,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 66,
                    "data": {
                        "text/plain": "   FAILURE_TARGET REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  WELL_GROUP  \\\n0               0              D                  L            R           6   \n1               0              D                  L            R           6   \n2               0              D                  L            R           6   \n3               0              D                  L            R           6   \n4               0              D                  L            R           6   \n\n   AGE_OF_EQUIPMENT      S15     S17    S13      S5  ...  S19_median  S19_max  \\\n0              1308  15.5184  188.10  36.29  4318.0  ...        22.4     28.9   \n1              1307  10.3032  149.24  36.78  4377.0  ...        22.4     28.9   \n2              1306  11.4480  187.45  35.84  4265.0  ...        22.4     28.9   \n3              1302  15.1368  148.33  37.53  4466.0  ...        22.4     28.9   \n4              1304  14.3736  179.30  36.31  4321.0  ...        22.4     28.9   \n\n   S19_min    S5_chg   S13_chg   S15_chg   S16_chg   S17_chg   S18_chg  \\\n0     22.4  0.989654  0.989779  1.208706  0.913224  1.150727  0.995684   \n1     22.4  1.001165  1.001141  0.800762  0.799231  0.931453  0.991996   \n2     22.4  0.974444  0.974443  0.886546  0.906484  1.158515  0.985806   \n3     22.4  1.015319  1.015344  1.168344  0.992329  0.922866  0.973863   \n4     22.4  0.983099  0.983085  1.094500  0.902220  1.132530  0.980886   \n\n    S19_chg  \n0  0.911805  \n1  0.911805  \n2  0.911805  \n3  0.911805  \n4  0.911805  \n\n[5 rows x 49 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FAILURE_TARGET</th>\n      <th>REGION_CLUSTER</th>\n      <th>MAINTENANCE_VENDOR</th>\n      <th>MANUFACTURER</th>\n      <th>WELL_GROUP</th>\n      <th>AGE_OF_EQUIPMENT</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>S5</th>\n      <th>...</th>\n      <th>S19_median</th>\n      <th>S19_max</th>\n      <th>S19_min</th>\n      <th>S5_chg</th>\n      <th>S13_chg</th>\n      <th>S15_chg</th>\n      <th>S16_chg</th>\n      <th>S17_chg</th>\n      <th>S18_chg</th>\n      <th>S19_chg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>D</td>\n      <td>L</td>\n      <td>R</td>\n      <td>6</td>\n      <td>1308</td>\n      <td>15.5184</td>\n      <td>188.10</td>\n      <td>36.29</td>\n      <td>4318.0</td>\n      <td>...</td>\n      <td>22.4</td>\n      <td>28.9</td>\n      <td>22.4</td>\n      <td>0.989654</td>\n      <td>0.989779</td>\n      <td>1.208706</td>\n      <td>0.913224</td>\n      <td>1.150727</td>\n      <td>0.995684</td>\n      <td>0.911805</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>D</td>\n      <td>L</td>\n      <td>R</td>\n      <td>6</td>\n      <td>1307</td>\n      <td>10.3032</td>\n      <td>149.24</td>\n      <td>36.78</td>\n      <td>4377.0</td>\n      <td>...</td>\n      <td>22.4</td>\n      <td>28.9</td>\n      <td>22.4</td>\n      <td>1.001165</td>\n      <td>1.001141</td>\n      <td>0.800762</td>\n      <td>0.799231</td>\n      <td>0.931453</td>\n      <td>0.991996</td>\n      <td>0.911805</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>D</td>\n      <td>L</td>\n      <td>R</td>\n      <td>6</td>\n      <td>1306</td>\n      <td>11.4480</td>\n      <td>187.45</td>\n      <td>35.84</td>\n      <td>4265.0</td>\n      <td>...</td>\n      <td>22.4</td>\n      <td>28.9</td>\n      <td>22.4</td>\n      <td>0.974444</td>\n      <td>0.974443</td>\n      <td>0.886546</td>\n      <td>0.906484</td>\n      <td>1.158515</td>\n      <td>0.985806</td>\n      <td>0.911805</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>D</td>\n      <td>L</td>\n      <td>R</td>\n      <td>6</td>\n      <td>1302</td>\n      <td>15.1368</td>\n      <td>148.33</td>\n      <td>37.53</td>\n      <td>4466.0</td>\n      <td>...</td>\n      <td>22.4</td>\n      <td>28.9</td>\n      <td>22.4</td>\n      <td>1.015319</td>\n      <td>1.015344</td>\n      <td>1.168344</td>\n      <td>0.992329</td>\n      <td>0.922866</td>\n      <td>0.973863</td>\n      <td>0.911805</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>D</td>\n      <td>L</td>\n      <td>R</td>\n      <td>6</td>\n      <td>1304</td>\n      <td>14.3736</td>\n      <td>179.30</td>\n      <td>36.31</td>\n      <td>4321.0</td>\n      <td>...</td>\n      <td>22.4</td>\n      <td>28.9</td>\n      <td>22.4</td>\n      <td>0.983099</td>\n      <td>0.983085</td>\n      <td>1.094500</td>\n      <td>0.902220</td>\n      <td>1.132530</td>\n      <td>0.980886</td>\n      <td>0.911805</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 49 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 5.0 More data transformation and feature engineering <a id=\"more\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Convert the categorical variables into binary dummy variables. We need to do this because the XGBT model (below) doesn't like categorical fields."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_dv = pd.get_dummies(df_balanced['REGION_CLUSTER'])\n\ndf_dv=df_dv.rename(columns={\"A\": \"CLUSTER_A\",\"B\":\"CLUSTER_B\",\"C\":\"CLUSTER_C\",\"D\":\"CLUSTER_D\",\"E\":\"CLUSTER_E\",\"F\":\"CLUSTER_F\",\"G\":\"CLUSTER_G\",\"H\":\"CLUSTER_H\"})\n\n\ndf_balanced= pd.concat([df_balanced, df_dv], axis=1)\n\n\ndf_dv = pd.get_dummies(df_balanced['MAINTENANCE_VENDOR'])\n\ndf_dv=df_dv.rename(columns={\"I\": \"MV_I\",\"J\":\"MV_J\",\"K\":\"MV_K\",\"L\":\"MV_L\",\"M\":\"MV_M\",\"N\":\"MV_N\",\"O\":\"MV_O\",\"P\":\"MV_P\"})\n\n\ndf_balanced = pd.concat([df_balanced, df_dv], axis=1)\n\n\n\ndf_dv = pd.get_dummies(df_balanced['MANUFACTURER'])\n\ndf_dv=df_dv.rename(columns={\"Q\": \"MN_Q\",\"R\":\"MN_R\",\"S\":\"MN_S\",\"T\":\"MN_T\",\"U\":\"MN_U\",\"V\":\"MN_V\",\"W\":\"MN_W\",\"X\":\"MN_X\",\"Y\":\"MN_Y\",\"Z\":\"MN_Z\"})\n\n\ndf_balanced = pd.concat([df_balanced, df_dv], axis=1)\n\n\ndf_dv = pd.get_dummies(df_balanced['WELL_GROUP'])\n\ndf_dv=df_dv.rename(columns={1: \"WG_1\",2:\"WG_2\",3:\"WG_3\",4:\"WG_4\",5:\"WG_5\",6:\"WG_6\",7:\"WG_7\",8:\"WG_8\"})\n\n\ndf_balanced = pd.concat([df_balanced, df_dv], axis=1)\n",
            "execution_count": 67,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Execute the same transformation on the train_test data set."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_dv = pd.get_dummies(df_train_test['REGION_CLUSTER'])\n\ndf_dv=df_dv.rename(columns={\"A\": \"CLUSTER_A\",\"B\":\"CLUSTER_B\",\"C\":\"CLUSTER_C\",\"D\":\"CLUSTER_D\",\"E\":\"CLUSTER_E\",\"F\":\"CLUSTER_F\",\"G\":\"CLUSTER_G\",\"H\":\"CLUSTER_H\"})\n\n\ndf_train_test= pd.concat([df_train_test, df_dv], axis=1)\n\n\ndf_dv = pd.get_dummies(df_train_test['MAINTENANCE_VENDOR'])\n\ndf_dv=df_dv.rename(columns={\"I\": \"MV_I\",\"J\":\"MV_J\",\"K\":\"MV_K\",\"L\":\"MV_L\",\"M\":\"MV_M\",\"N\":\"MV_N\",\"O\":\"MV_O\",\"P\":\"MV_P\"})\n\n\ndf_train_test = pd.concat([df_train_test, df_dv], axis=1)\n\n\n\ndf_dv = pd.get_dummies(df_train_test['MANUFACTURER'])\n\ndf_dv=df_dv.rename(columns={\"Q\": \"MN_Q\",\"R\":\"MN_R\",\"S\":\"MN_S\",\"T\":\"MN_T\",\"U\":\"MN_U\",\"V\":\"MN_V\",\"W\":\"MN_W\",\"X\":\"MN_X\",\"Y\":\"MN_Y\",\"Z\":\"MN_Z\"})\n\n\ndf_train_test = pd.concat([df_train_test, df_dv], axis=1)\n\n\ndf_dv = pd.get_dummies(df_train_test['WELL_GROUP'])\n\ndf_dv=df_dv.rename(columns={1: \"WG_1\",2:\"WG_2\",3:\"WG_3\",4:\"WG_4\",5:\"WG_5\",6:\"WG_6\",7:\"WG_7\",8:\"WG_8\"})\n\n\ndf_train_test = pd.concat([df_train_test, df_dv], axis=1)\n\n",
            "execution_count": 68,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "And, also on the df_total data set."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_dv = pd.get_dummies(df_total['REGION_CLUSTER'])\n\ndf_dv=df_dv.rename(columns={\"A\": \"CLUSTER_A\",\"B\":\"CLUSTER_B\",\"C\":\"CLUSTER_C\",\"D\":\"CLUSTER_D\",\"E\":\"CLUSTER_E\",\"F\":\"CLUSTER_F\",\"G\":\"CLUSTER_G\",\"H\":\"CLUSTER_H\"})\n\n\ndf_total= pd.concat([df_total, df_dv], axis=1)\n\n\ndf_dv = pd.get_dummies(df_total['MAINTENANCE_VENDOR'])\n\ndf_dv=df_dv.rename(columns={\"I\": \"MV_I\",\"J\":\"MV_J\",\"K\":\"MV_K\",\"L\":\"MV_L\",\"M\":\"MV_M\",\"N\":\"MV_N\",\"O\":\"MV_O\",\"P\":\"MV_P\"})\n\n\ndf_total = pd.concat([df_total, df_dv], axis=1)\n\n\n\ndf_dv = pd.get_dummies(df_total['MANUFACTURER'])\n\ndf_dv=df_dv.rename(columns={\"Q\": \"MN_Q\",\"R\":\"MN_R\",\"S\":\"MN_S\",\"T\":\"MN_T\",\"U\":\"MN_U\",\"V\":\"MN_V\",\"W\":\"MN_W\",\"X\":\"MN_X\",\"Y\":\"MN_Y\",\"Z\":\"MN_Z\"})\n\n\ndf_total = pd.concat([df_total, df_dv], axis=1)\n\n\ndf_dv = pd.get_dummies(df_total['WELL_GROUP'])\n\ndf_dv=df_dv.rename(columns={1: \"WG_1\",2:\"WG_2\",3:\"WG_3\",4:\"WG_4\",5:\"WG_5\",6:\"WG_6\",7:\"WG_7\",8:\"WG_8\"})\n\n\ndf_total = pd.concat([df_total, df_dv], axis=1)",
            "execution_count": 69,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 6.0 Build the model on the balanced training data set <a id=\"build\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Remove the newly redundant categorical variables.  This are now represented by dummy variables.\ndf_balanced=df_balanced.drop(columns=['REGION_CLUSTER','MAINTENANCE_VENDOR','MANUFACTURER','WELL_GROUP'])",
            "execution_count": 70,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "In the balanced data set, separate the dependent and independent variables to feed the model development process."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\nfeatures = [x for x in df_balanced.columns if x not in ['FAILURE_TARGET','EQUIPMENT_FAILURE']]  \ndependent=pd.DataFrame(df_balanced['FAILURE_TARGET'])\n\nindependent=df_balanced.drop(columns=['FAILURE_TARGET'])",
            "execution_count": 71,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#make sure everything is numeric for simplicity\nindependent = independent.apply(pd.to_numeric) \ndf_balanced = df_balanced.apply(pd.to_numeric)",
            "execution_count": 72,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Define model specs."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import matplotlib.pylab as plt\n%matplotlib inline\n\ndef evaluate_model(alg, train, target, predictors,  early_stopping_rounds=1):\n    \n   \n    #Fit the algorithm on the data\n    alg.fit(train[predictors], target['FAILURE_TARGET'], eval_metric='auc')\n        \n    #Predict training set:\n    dtrain_predictions = alg.predict(train[predictors])\n    dtrain_predprob = alg.predict_proba(train[predictors])[:,1]\n    \n    feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False) \n    feat_imp.plot(kind='bar', title='Feature Importance', color='g') \n    plt.ylabel('Feature Importance Score')\n        \n    #Print model report:\n    print(\"\\nModel Report\")\n    print(\"Accuracy : %.4g\" % metrics.accuracy_score(target['FAILURE_TARGET'].values, dtrain_predictions))\n    print(\"AUC Score (Balanced): %f\" % metrics.roc_auc_score(target['FAILURE_TARGET'], dtrain_predprob))",
            "execution_count": 73,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We are initializing our model with default model parameters. Note that we could probably improve the results by tweaking the parameters, but we will save that exercise for another day. "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xgb0 = XGBClassifier(\n objective= 'binary:logistic')\n\n",
            "execution_count": 74,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 7.0 Evaluate the Model <a id=\"score\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Probably the most confusing element of PM problems is building a realistic assessment of the model.  Because of timing and the small number of failures, understanding how the model will work once deployed in production is challenging. \n\nThere are standard metrics for evaluating models like accuracy, AUC, and a confusion matrix.  In sections 7.1 and 7.2, I will show how, given the transformations we used to build our model and the complexity of the problem, these metrics do not give us a realistic view of model performance when deployed into production.  These standard metrics are definitely useful but are not sufficient.\n\nIn section 7.3, I lay out how I typically evaluate PM models."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 7.1 Evaluate the model using an AUC and accuacy metrics.<a id=\"7.1\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "First, we will evaluate the balanced training data with the default, a 50% cut-off.\n\nFor information on how to find the best cut-off for these types of problems, please see the following.\n\nhttps://medium.com/swlh/determining-a-cut-off-or-threshold-when-working-with-a-binary-dependent-target-variable-7c2342cf2a7c"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "evaluate_model(xgb0, independent, dependent,features) ",
            "execution_count": 75,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "\nModel Report\nAccuracy : 0.8346\nAUC Score (Balanced): 0.915649\n",
                    "name": "stdout"
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<Figure size 432x288 with 1 Axes>",
                        "image/png": "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\n"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "With a cut-off of 50%, the accuracy is .835, and the AUC is .916 on the balanced training data.\n\nThese results are not bad, but there are a few issues.  Balancing the data significantly alters your base probability of failure.  Remember, before we applied the SMOTE algorithm, about 3.8% of our records were labeled as a FAILURE_TARGET.  After using the SMOTE algorithm, 50% were failures.  Because of this, I always prefer to evaluate the model on the unbalanced data.  Below we will examine the unbalanced data with a 50% cut-off.\n\nAlso, note that the predicted probability from our model is based on the balanced data.  This means it is not the true probability of failure.  The true probability of failure will be closer to .14%, not 50%.  The .14% comes from an average of the original failure variable. (EQUIPMENT_FAILURE).  \n\nI am using the term \"probability,\" perhaps a little too loosely in this article.  Just understand that the probability that the equipment will fail in the real world is about .14% (based on EQUIPMENT_FAILURE).  The likelihood of selecting a day within 28 days of a failure (FAILURE_TARGET) is about 3.8%.  The probability of a failure after we balance the data is 50%.\n "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Isolate the unbalanced training and testing data sets."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\ndf_testing=df_train_test[df_train_test['MODELING_GROUP'] == 'TESTING'].copy()\ndf_training=df_train_test[df_train_test['MODELING_GROUP'] != 'TESTING'].copy()",
            "execution_count": 76,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\n\ndf_training['P_FAIL']= xgb0.predict_proba(df_training[features])[:,1];\ndf_training['Y_FAIL'] = np.where(((df_training.P_FAIL <= .50)), 0, 1)\n#Print model report:\nprint(\"Accuracy : %.4g\" % metrics.accuracy_score(df_training['FAILURE_TARGET'].values, df_training['Y_FAIL']))\nprint(\"AUC Score (Train): %f\" % metrics.roc_auc_score(df_training['FAILURE_TARGET'], df_training['P_FAIL']))",
            "execution_count": 77,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Accuracy : 0.7863\nAUC Score (Train): 0.891580\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "With a 50% cut-off, we get an accuracy of .79 and an AUC of .89\n\nNow, lets' try with a 67% cut-off. Probabilities larger than 67% are labeled as failures. Probabilities less than or equal to 67% are labeled as non-failures.  "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_training['P_FAIL']= xgb0.predict_proba(df_training[features])[:,1];\ndf_training['Y_FAIL'] = np.where(((df_training.P_FAIL <= .67)), 0, 1)\n#Print model report:\nprint(\"Accuracy : %.4g\" % metrics.accuracy_score(df_training['FAILURE_TARGET'].values, df_training['Y_FAIL']))\nprint(\"AUC Score (Train): %f\" % metrics.roc_auc_score(df_training['FAILURE_TARGET'], df_training['P_FAIL']))",
            "execution_count": 78,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Accuracy : 0.9504\nAUC Score (Train): 0.891580\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The accuracy improves quite a bit.  Now, let's apply the model to the testing data set."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_testing['P_FAIL']= xgb0.predict_proba(df_testing[features])[:,1];\ndf_testing['Y_FAIL'] = np.where(((df_testing.P_FAIL <= .67)), 0, 1)\n#Print model report:\nprint(\"Accuracy : %.4g\" % metrics.accuracy_score(df_testing['FAILURE_TARGET'].values, df_testing['Y_FAIL']))\nprint(\"AUC Score (Test): %f\" % metrics.roc_auc_score(df_testing['FAILURE_TARGET'], df_testing['P_FAIL']))",
            "execution_count": 79,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Accuracy : 0.9415\nAUC Score (Test): 0.588301\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Before we go any further, let's take a step back and think about what we have done.  Ok, so our model validates with an accuracy of .942.  \n\nIs that good or bad?  \n\nAt this point, I honestly have no idea.  I mean, what does this say about how this model will perform in \"The Wild\"?  \n\nI don't think we can know if this is good or bad.  To fully grasp how a model will perform, you have to put it into the context of its deployment.  In the next section, I will attempt, but fail, to do this with a confusion matrix."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 7.2 Evaluating with a Confusion Matrix.<a id=\"7.2\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Previously, we looked at the AUC and accuracy as ways to evaluate a predictive maintenance model.  I don't think they cut the mustard, honestly.  A confusion matrix is better because it directly correlates to the cost structure of the problem. \n\n\nA confusion matrix specifically lays out the following metrics.\n1. True Positive.  The model predicts the machine will fail, and it does.\n2. True Negative.  The model predicts the machine will not fail and it does not fail.\n3. False Positive.  The model predicts the machine will fail and it does not fail.\n4. False Negative.  The model predicts the machine will not fail and it fails.\n\nThese metrics directly correlate to the economic costs of our PM problem.\n\n\n\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Remember this?"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from IPython.display import Image\nfrom IPython.core.display import HTML \nImage(url= \"https://cdn-images-1.medium.com/max/1600/1*fUKUEUeqgIYU9xlxj4pwhw.png\")",
            "execution_count": 80,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 80,
                    "data": {
                        "text/html": "<img src=\"https://cdn-images-1.medium.com/max/1600/1*fUKUEUeqgIYU9xlxj4pwhw.png\"/>",
                        "text/plain": "<IPython.core.display.Image object>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "A false positive is \u201cUnnecessary Maintenance.\u201d   When your model predicts failure and is not going to fail, you incur unnecessary maintenance costs.\n\nA true positive is \u201cTimely and Appropriate Maintenance.\u201d When your model predicts failure, and it is going to fail, you incur timely and appropriate maintenance costs.\n\nA false negative is \u201cMachine Runs to Failure.\u201d When your model does not predict failure and fails, you incur costs associated with running your machine to failure.\n\nFor this use case, this means that a false positive costs $1,500.   \n\nA false negative costs $30,000.   \n\nA true positive costs $7,500. \n\nA true negative has no cost because no action is taken.\n\nA confusion matrix lays out what is important for us to evaluate.\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "A confusion matrix is a cross-tabulation between the binary prediction of failure/non-failure and the actual binary failure/non-failure variable.  Remember that we have two actual failure values.\n\nThe first is the original failure variable, 'EQUIPMENT_FAILURE.'\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xxxx = pd.DataFrame(pd_data.groupby(['EQUIPMENT_FAILURE'])['ID'].agg('count'))\nxxxx",
            "execution_count": 81,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 81,
                    "data": {
                        "text/plain": "                       ID\nEQUIPMENT_FAILURE        \n0                  307330\n1                     421",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n    </tr>\n    <tr>\n      <th>EQUIPMENT_FAILURE</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>307330</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>421</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "'EQUIPMENT_FAILURE' has 421 failure indicators.  Remember that a '1' appears on the day that the failure occurs.  \n\nLet's examine a cross-tab of 'EQUIPMENT_FAILURE' with the predicted binary failure variable for the testing data set ('Y_FAIL')."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(pd.crosstab(df_testing.Y_FAIL, df_testing.EQUIPMENT_FAILURE, dropna=False))",
            "execution_count": 82,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "EQUIPMENT_FAILURE       0    1\nY_FAIL                        \n0                  105977  108\n1                    2793   41\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "According to the confusion matrix above, we have 41 true positives, 108 false negatives, 2793 false positives, and 105,977 true negatives.  \n\nIs this right?  \n\nNo, it isn't.  Think about it.  \n\nThe 'EQUIPMENT_FAILURE' variable identifies a failure on the day it occurs.  Let's say that failure occurs on Friday, and we have signals for failure on Monday, Tuesday, Wednesday, and Thursday, but not on Friday.  I would argue that the failure on Friday is a True Positive, given that there were four failure signals in the days leading up to the failure.  However, the confusion matrix above counts Monday, Tuesday, Wednesday, and Thursday as false positives and Friday as a false negative.  This doesn't work, does it?\n\n\nNow, we will create a confusion matrix using 'FAILURE_TARGET.'  This is the predicted binary variable where the 28 days leading up to a failure are flagged with a '1'."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(pd.crosstab(df_testing.Y_FAIL, df_testing.FAILURE_TARGET, dropna=False))",
            "execution_count": 83,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "FAILURE_TARGET       0     1\nY_FAIL                      \n0               102240  3845\n1                 2528   306\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "With 'FAILURE_TARGET,' we have 306 True Positives, 3,845 False Negatives, 2,528 False Positives, and 102,240 True Negatives.  \n\nDoes this work?  \n\nNot really, huh.  Think about it.  \n\nEach failure is represented 28 different times. If a machine fails on Friday the 28th, the previous twenty-seven days of the month are also flagged as a failure.  \n\nFriday can be a true positive, the previous Wednesday a true positive, and the previous Thursday a false positive.  \n\nThe example above clearly does not reflect what we can expect when we push this model into production."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "So, what does all this mean?  To get an accurate accounting of how the model will work in production, we use additional logic and business rules/heuristics."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 7.3 Using Heuristics to Define a False Positive, True Positive, False Negative, and True Negative.<a id=\"7.3\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "To accurately evaluate our machine learning model, we first need to define a few parameters.  I usually fine-tune these parameters with the testing and training data sets, then confirm the accuracy with the validation data set.\n\nThe first parameter is the Forecast Window.  \n\nThe Forecast Window is the length of time a failure signal projects into the future.  \n\nFor example, if there is a failure signal on June 1st, how long is that signal good for?  \n\nDoes it mean the machine will break in the next second, minute, hour, day, or month? \n\nNote that the length of the forecast window depends on the context of the problem.  If a machine runs to failure in 10 years, the forecast window will be relatively long, perhaps as long as six or nine months.  If a machine runs to failure in 1 day, the forecast window will be much shorter, maybe an hour or a few minutes.  The length of the forecast window must be helpful to the problem.  For example, a twenty-eight-day forecast window for a machine that runs to failure in thirty days is of little value.  \n\nIn our current use case, the machine runs to failure in four to six years, so a ninety-day forecast window is reasonable."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "forecast_window=90",
            "execution_count": 84,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now that we defined the forecast window we will now apply it to the data.  This means that a signal is good for ninety days.  For example, if a signal appears on January 1st, that signal is good until March 31st (ninety days)"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We will create a new failure indicator.  \n\nThis failure indicator (signal) can only appear every ninety days.  Note that we have panel data and must ensure that the signals don't \"bleed\" from one machine to the next.  For example, if a signal occurs on machine X's last possible day, we do not want the window for machine X+1 to be affected by this signal."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Score df_train_test"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_train_test['P_FAIL']= xgb0.predict_proba(df_train_test[features])[:,1];\ndf_train_test['Y_FAIL'] = np.where(((df_train_test.P_FAIL <= .67)), 0, 1)",
            "execution_count": 85,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#sort the data by id and date.\nxx=df_train_test\nxx=xx.sort_values(by=['ID','DATE'], ascending=[True, True])",
            "execution_count": 86,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#create a unique list of machines\naa=xx\n\npd_id=aa.drop_duplicates(subset='ID')\npd_id=pd_id[['ID']]\npd_id.shape",
            "execution_count": 87,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 87,
                    "data": {
                        "text/plain": "(295, 1)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#label each machine with a sequential number\npd_id=pd_id.reset_index(drop=True)\npd_id=pd_id.reset_index(drop=False)\npd_id=pd_id.rename(columns={\"index\": \"SCOOBYDOO\"})\npd_id['SCOOBYDOO']=pd_id['SCOOBYDOO']+1\npd_id.head()",
            "execution_count": 88,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 88,
                    "data": {
                        "text/plain": "   SCOOBYDOO      ID\n0          1  100001\n1          2  100002\n2          3  100014\n3          4  100017\n4          5  100018",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SCOOBYDOO</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>100001</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>100002</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>100014</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>100017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>100018</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#grab the max number of machines +1\n\ncolumn = pd_id[\"SCOOBYDOO\"]\nmax_value = column.max()+1\nmax_value",
            "execution_count": 89,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 89,
                    "data": {
                        "text/plain": "296"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#append sequential number to main file\nxx=xx.sort_values(by=['ID'], ascending=[True])\npd_id=pd_id.sort_values(by=['ID'], ascending=[True])\nxx =xx.merge(pd_id, on=['ID'], how='inner')\nxx.head()",
            "execution_count": 90,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 90,
                    "data": {
                        "text/plain": "   index      ID       DATE REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  \\\n0      0  100001 2014-12-02              G                  O            Y   \n1      1  100001 2016-03-29              G                  O            Y   \n2      2  100001 2016-03-30              G                  O            Y   \n3      3  100001 2016-03-31              G                  O            Y   \n4      4  100001 2016-04-01              G                  O            Y   \n\n   WELL_GROUP     S15         S17    S13  ...  WG_2  WG_3  WG_4  WG_5  WG_6  \\\n0           1  11.088  145.223448  39.34  ...     0     0     0     0     0   \n1           1  18.960    0.000000  38.87  ...     0     0     0     0     0   \n2           1  29.040    0.000000  37.36  ...     0     0     0     0     0   \n3           1  18.000    0.000000  38.81  ...     0     0     0     0     0   \n4           1  26.160    0.000000  39.47  ...     0     0     0     0     0   \n\n   WG_7  WG_8    P_FAIL  Y_FAIL  SCOOBYDOO  \n0     0     0  0.349602       0          1  \n1     0     0  0.644506       0          1  \n2     0     0  0.449370       0          1  \n3     0     0  0.644506       0          1  \n4     0     0  0.616145       0          1  \n\n[5 rows x 95 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>ID</th>\n      <th>DATE</th>\n      <th>REGION_CLUSTER</th>\n      <th>MAINTENANCE_VENDOR</th>\n      <th>MANUFACTURER</th>\n      <th>WELL_GROUP</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>...</th>\n      <th>WG_2</th>\n      <th>WG_3</th>\n      <th>WG_4</th>\n      <th>WG_5</th>\n      <th>WG_6</th>\n      <th>WG_7</th>\n      <th>WG_8</th>\n      <th>P_FAIL</th>\n      <th>Y_FAIL</th>\n      <th>SCOOBYDOO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>100001</td>\n      <td>2014-12-02</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>11.088</td>\n      <td>145.223448</td>\n      <td>39.34</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.349602</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>100001</td>\n      <td>2016-03-29</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>18.960</td>\n      <td>0.000000</td>\n      <td>38.87</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.644506</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>100001</td>\n      <td>2016-03-30</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>29.040</td>\n      <td>0.000000</td>\n      <td>37.36</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.449370</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>100001</td>\n      <td>2016-03-31</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>18.000</td>\n      <td>0.000000</td>\n      <td>38.81</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.644506</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>100001</td>\n      <td>2016-04-01</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>26.160</td>\n      <td>0.000000</td>\n      <td>39.47</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.616145</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 95 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#sort data\nxx=xx.sort_values(by=['ID','DATE'], ascending=[True,True])\n\n#reset index\nxx=xx.reset_index(drop=True)",
            "execution_count": 91,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#create a null dataframe for the next step\ndf_fred=xx\ndf_fred['Y_FAIL_sumxx']=0\ndf_fred=df_fred[df_fred['SCOOBYDOO'] == max_value+1]\ndf_fred.shape",
            "execution_count": 92,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 92,
                    "data": {
                        "text/plain": "(0, 96)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The next few steps assign a new failure indicator that incorporates the forecast window.  Note, this calculation occurs at a machine level.  Doing this keeps a signal from one machine affecting another machine. \n\n This takes a while to run."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#sum the number of signals occuring over the last 90 days for each machine individually\n\nfor x in range(max_value):\n        dffx=xx[xx['SCOOBYDOO'] ==x]\n        dff=dffx.copy()\n        dff['Y_FAIL_sumxx'] =(dff['Y_FAIL'].rolling(min_periods=1, window=(forecast_window)).sum())\n        df_fred= pd.concat([df_fred,dff])",
            "execution_count": 93,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xx=df_fred",
            "execution_count": 94,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xx.head(2)",
            "execution_count": 95,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 95,
                    "data": {
                        "text/plain": "   index      ID       DATE REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  \\\n0      0  100001 2014-12-02              G                  O            Y   \n1    549  100001 2014-12-03              G                  O            Y   \n\n   WELL_GROUP        S15         S17    S13  ...  WG_3  WG_4  WG_5  WG_6  \\\n0           1  11.088000  145.223448  39.34  ...     0     0     0     0   \n1           1   8.877943  187.573214  39.20  ...     0     0     0     0   \n\n   WG_7  WG_8    P_FAIL  Y_FAIL  SCOOBYDOO  Y_FAIL_sumxx  \n0     0     0  0.349602       0          1           0.0  \n1     0     0  0.307730       0          1           0.0  \n\n[2 rows x 96 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>ID</th>\n      <th>DATE</th>\n      <th>REGION_CLUSTER</th>\n      <th>MAINTENANCE_VENDOR</th>\n      <th>MANUFACTURER</th>\n      <th>WELL_GROUP</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>...</th>\n      <th>WG_3</th>\n      <th>WG_4</th>\n      <th>WG_5</th>\n      <th>WG_6</th>\n      <th>WG_7</th>\n      <th>WG_8</th>\n      <th>P_FAIL</th>\n      <th>Y_FAIL</th>\n      <th>SCOOBYDOO</th>\n      <th>Y_FAIL_sumxx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>100001</td>\n      <td>2014-12-02</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>11.088000</td>\n      <td>145.223448</td>\n      <td>39.34</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.349602</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549</td>\n      <td>100001</td>\n      <td>2014-12-03</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.877943</td>\n      <td>187.573214</td>\n      <td>39.20</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.307730</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows \u00d7 96 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# if a signal has occured in the last 90 days, the signal is 0.\nxx['Y_FAILZ']=np.where((xx.Y_FAIL_sumxx>1), 0, xx.Y_FAIL)",
            "execution_count": 96,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now that we have defined the failure window and used this definition to clean up the failure indicator, we now need to associate the failure indicators or signals with the actual failures to determine prediction accuracy.\n\nIn the next few steps, we will create a unique id for each failure signal, the machine (ID) associated with each signal, and each signal's date."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#sort the data by id and date.\n\nxx=xx.sort_values(by=['ID','DATE'], ascending=[True, True])\n",
            "execution_count": 97,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#create signal id with the cumsum function.\nxx['SIGNAL_ID'] = xx['Y_FAILZ'].cumsum()\n\n",
            "execution_count": 98,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now we will pull the records with a signal into a different data frame. \n\nHere we will create a new field that identifies the date of each signal (SIGNAL_DATE). \n\nAlso, we will identify the ID Associated with each signal (ID_OF_SIGNAL)\n\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_signals=xx[xx['Y_FAILZ'] == 1]\ndf_signal_date=df_signals[['SIGNAL_ID','DATE','ID']]\ndf_signal_date=df_signal_date.rename(index=str, columns={\"DATE\": \"SIGNAL_DATE\"})\ndf_signal_date=df_signal_date.rename(index=str, columns={\"ID\": \"ID_OF_SIGNAL\"})",
            "execution_count": 99,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We have a total of 536 signals.  Now each has a unique id. "
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "df_signal_date.shape",
            "execution_count": 100,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 100,
                    "data": {
                        "text/plain": "(394, 3)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Append SIGNAL_ID to the primary data frame.  "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xx =xx.merge(df_signal_date, on=['SIGNAL_ID'], how='outer')",
            "execution_count": 101,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Simplify by only keeping the fields we need going forward."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xx=xx[['DATE', 'ID', 'EQUIPMENT_FAILURE', 'FAILURE_TARGET','FAILURE_DATE',\n       'P_FAIL', 'Y_FAILZ','SIGNAL_ID',\n       'SIGNAL_DATE','ID_OF_SIGNAL','MODELING_GROUP']]",
            "execution_count": 102,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": " Create a field called \"Warning\" that indicates the time from signal to failure."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\nxx['C'] = xx['FAILURE_DATE'] - xx['SIGNAL_DATE']\nxx['WARNING'] = xx['C'] / np.timedelta64(1, 'D')\n\n",
            "execution_count": 103,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Finally, we have enough information to define a false positive, false negative, true positive, and true negative. \n\nMy definition makes sense here but is unique to this specific business problem.\n\nA true positive occurs if and only if the machine fails, and there was a signal within the last 90 days. Also, we have to ensure that the signal id belongs to the machine (ID). Note that this prohibits a signal from another machine from being applied to the machine in question.\n\nA false negative occurs if and only if the machine fails, and it is not a true positive.\n\nA False Positive occurs if there is a failure signal, and a failure does not happen in the next 90 days. Also, if a signal occurs after the failure, this is a false positive. We also have to ensure that the signal ID belongs to the machine ID. Note that this prohibits a signal from another machine from being applied to the machine in question.\n\nIf an observation is not a False Positive, a False Negative, or a True Positive, it is a True Negative.\n\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define a true positive\nxx['TRUE_POSITIVE'] = np.where(((xx.EQUIPMENT_FAILURE == 1) & (xx.WARNING<=forecast_window) &(xx.WARNING>=0) & (xx.ID_OF_SIGNAL==xx.ID)), 1, 0)",
            "execution_count": 104,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define a false negative\nxx['FALSE_NEGATIVE'] = np.where((xx.TRUE_POSITIVE==0) & (xx.EQUIPMENT_FAILURE==1), 1, 0)",
            "execution_count": 105,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define a false positive\nxx['BAD_S']=np.where((xx.WARNING<0) | (xx.WARNING>=forecast_window), 1, 0)\n\nxx['FALSE_POSITIVE'] = np.where(((xx.Y_FAILZ == 1) & (xx.BAD_S==1) & (xx.ID_OF_SIGNAL==xx.ID)), 1, 0)",
            "execution_count": 106,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xx['bootie']=1",
            "execution_count": 107,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xx['CATEGORY']=np.where((xx.FALSE_POSITIVE==1),'FALSE_POSITIVE',\n                                      (np.where((xx.FALSE_NEGATIVE==1),'FALSE_NEGATIVE',\n                                                (np.where((xx.TRUE_POSITIVE==1),'TRUE_POSITIVE','TRUE_NEGATIVE')))))",
            "execution_count": 108,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "table = pd.pivot_table(xx, values=['bootie'], index=['MODELING_GROUP'],columns=['CATEGORY'], aggfunc=np.sum)\ntable",
            "execution_count": 109,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 109,
                    "data": {
                        "text/plain": "                       bootie                                           \nCATEGORY       FALSE_NEGATIVE FALSE_POSITIVE TRUE_NEGATIVE TRUE_POSITIVE\nMODELING_GROUP                                                          \nTESTING                    98            131        108639            51\nTRAINING                   41            107        106473           105",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">bootie</th>\n    </tr>\n    <tr>\n      <th>CATEGORY</th>\n      <th>FALSE_NEGATIVE</th>\n      <th>FALSE_POSITIVE</th>\n      <th>TRUE_NEGATIVE</th>\n      <th>TRUE_POSITIVE</th>\n    </tr>\n    <tr>\n      <th>MODELING_GROUP</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>TESTING</th>\n      <td>98</td>\n      <td>131</td>\n      <td>108639</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>TRAINING</th>\n      <td>41</td>\n      <td>107</td>\n      <td>106473</td>\n      <td>105</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "So, in the training data set, we have 41 false negatives, 107 false positives, 106,473 true negatives, and 105 true positives. "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now we can apply the same logic to the validation data set to make sure it is not sample-specific."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 7.4 Apply Model and Heuristics the Training, Testing and Validation Data Sets. <a id=\"7.4\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Predict the probability of failure for all records."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a predicted failure indicator based on a cut-off of .67."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\ndf_total['P_FAIL']= xgb0.predict_proba(df_total[features])[:,1];\ndf_total['Y_FAIL'] = np.where(((df_total.P_FAIL <= .67)), 0, 1)",
            "execution_count": 110,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Define the forecast window."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "forecast_window=90",
            "execution_count": 111,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Ensure that the failure indicator occurs only once every 90 days."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#get a the number of machines +1 and label each machine with a sequential number.\n\naa=df_total\n\npd_id=aa.drop_duplicates(subset='ID')\npd_id=pd_id[['ID']]\npd_id=pd_id.reset_index(drop=True)\npd_id=pd_id.reset_index(drop=False)\npd_id=pd_id.rename(columns={\"index\": \"SCOOBYDOO\"})\npd_id['SCOOBYDOO']=pd_id['SCOOBYDOO']+1\n\ncolumn = pd_id[\"SCOOBYDOO\"]\nmax_value = column.max()+1\nmax_value\n",
            "execution_count": 112,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 112,
                    "data": {
                        "text/plain": "422"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy=df_total",
            "execution_count": 113,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "#append the sequential number back to the larger dataframe.\nyy=yy.sort_values(by=['ID'], ascending=[True])\npd_id=pd_id.sort_values(by=['ID'], ascending=[True])\nyy =yy.merge(pd_id, on=['ID'], how='inner')\nyy.head()",
            "execution_count": 114,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 114,
                    "data": {
                        "text/plain": "   index      ID       DATE REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  \\\n0      0  100001 2014-12-02              G                  O            Y   \n1    483  100001 2014-12-04              G                  O            Y   \n2    484  100001 2014-12-05              G                  O            Y   \n3    485  100001 2014-12-06              G                  O            Y   \n4    486  100001 2014-12-07              G                  O            Y   \n\n   WELL_GROUP        S15         S17    S13  ...  WG_2  WG_3  WG_4  WG_5  \\\n0           1  11.088000  145.223448  39.34  ...     0     0     0     0   \n1           1   8.676444  148.363704  38.87  ...     0     0     0     0   \n2           1   9.988338  133.660000  39.47  ...     0     0     0     0   \n3           1   8.475264  197.181600  40.33  ...     0     0     0     0   \n4           1   7.971100  164.545833  38.74  ...     0     0     0     0   \n\n   WG_6  WG_7  WG_8    P_FAIL  Y_FAIL  SCOOBYDOO  \n0     0     0     0  0.349602       0          1  \n1     0     0     0  0.363732       0          1  \n2     0     0     0  0.358921       0          1  \n3     0     0     0  0.294767       0          1  \n4     0     0     0  0.307730       0          1  \n\n[5 rows x 94 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>ID</th>\n      <th>DATE</th>\n      <th>REGION_CLUSTER</th>\n      <th>MAINTENANCE_VENDOR</th>\n      <th>MANUFACTURER</th>\n      <th>WELL_GROUP</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>...</th>\n      <th>WG_2</th>\n      <th>WG_3</th>\n      <th>WG_4</th>\n      <th>WG_5</th>\n      <th>WG_6</th>\n      <th>WG_7</th>\n      <th>WG_8</th>\n      <th>P_FAIL</th>\n      <th>Y_FAIL</th>\n      <th>SCOOBYDOO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>100001</td>\n      <td>2014-12-02</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>11.088000</td>\n      <td>145.223448</td>\n      <td>39.34</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.349602</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>483</td>\n      <td>100001</td>\n      <td>2014-12-04</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.676444</td>\n      <td>148.363704</td>\n      <td>38.87</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.363732</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>484</td>\n      <td>100001</td>\n      <td>2014-12-05</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>9.988338</td>\n      <td>133.660000</td>\n      <td>39.47</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.358921</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>485</td>\n      <td>100001</td>\n      <td>2014-12-06</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.475264</td>\n      <td>197.181600</td>\n      <td>40.33</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.294767</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>486</td>\n      <td>100001</td>\n      <td>2014-12-07</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>7.971100</td>\n      <td>164.545833</td>\n      <td>38.74</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.307730</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 94 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#sort data\nyy=yy.sort_values(by=['ID','DATE'], ascending=[True,True])",
            "execution_count": 115,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#reset index\nyy=yy.reset_index(drop=True)",
            "execution_count": 116,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\n#create a null dataframe for the next step\ndf_fred=yy\ndf_fred['Y_FAIL_sumxx']=0\ndf_fred=df_fred[df_fred['SCOOBYDOO'] == max_value+1]\ndf_fred.shape",
            "execution_count": 117,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 117,
                    "data": {
                        "text/plain": "(0, 95)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The next few steps assign a new failure indicator that incorporates the forecast window. Note, this calculation occurs at a machine level. This keeps a signal from one machine affecting another machine. This takes a while to run."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#sum the number of signals occuring over the last 90 days for each machine individually\nfor x in range(max_value):\n        dffx=yy[yy['SCOOBYDOO'] ==x]\n        dff=dffx.copy()\n        dff['Y_FAIL_sumxx'] =(dff['Y_FAIL'].rolling(min_periods=1, window=(forecast_window)).sum())\n        df_fred= pd.concat([df_fred,dff])\n        ",
            "execution_count": 118,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy=df_fred",
            "execution_count": 119,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# if a signal has occured in the last 90 days, the signal is 0.\n\nyy['Y_FAILZ']=np.where((yy.Y_FAIL_sumxx>1), 0, yy.Y_FAIL)",
            "execution_count": 120,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now that we have defined the failure window and used this definition to clean up the failure indicator, we now need to associate the failure indicators or signals with the actual failures to determine prediction accuracy.\n\nIn the next few steps, we will create a unique id for each failure signal, the machine (ID) associated with each signal, and each signal's date."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#sort the data by id and date.\nyy=yy.sort_values(by=['ID','DATE'], ascending=[True, True])",
            "execution_count": 121,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#create signal id with the cumsum function.\nyy['SIGNAL_ID'] = yy['Y_FAILZ'].cumsum()\n\n",
            "execution_count": 122,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now we will pull the records with a signal into a different data frame.\nHere we will create a new field that identifies the date of each signal (SIGNAL_DATE).\nAlso, we will identify the ID Associated with each signal (ID_OF_SIGNAL)"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#create the signal date and ID_OF_SIGNAL\n\nyy_signals=yy[yy['Y_FAILZ'] == 1]\nyy_signal_date=yy_signals[['SIGNAL_ID','DATE','ID']]\nyy_signal_date=yy_signal_date.rename(index=str, columns={\"DATE\": \"SIGNAL_DATE\"})\nyy_signal_date=yy_signal_date.rename(index=str, columns={\"ID\": \"ID_OF_SIGNAL\"})",
            "execution_count": 123,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#merge the two data frames back into one.\n\nyy =yy.merge(yy_signal_date, on=['SIGNAL_ID'], how='outer')\n",
            "execution_count": 124,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Keep on the fields we need\nyy=yy[['DATE', 'ID', 'EQUIPMENT_FAILURE', 'FAILURE_TARGET','FAILURE_DATE','MODELING_GROUP',\n       'P_FAIL', 'Y_FAILZ','SIGNAL_ID',\n       'SIGNAL_DATE','ID_OF_SIGNAL']]",
            "execution_count": 125,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Calculate the warning time between each failure date and signal date.\nyy['C'] = yy['FAILURE_DATE'] - yy['SIGNAL_DATE']\nyy['WARNING'] = yy['C'] / np.timedelta64(1, 'D')\nyy['WARNING'].fillna(9999, inplace=True)",
            "execution_count": 126,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Define true positives, true negatives, false positives, and false negatives."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define a true positive\nyy['TRUE_POSITIVE'] = np.where(((yy.EQUIPMENT_FAILURE == 1) & (yy.WARNING<=forecast_window) &(yy.WARNING>=0) & (yy.ID_OF_SIGNAL==yy.ID)), 1, 0)",
            "execution_count": 127,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define a false negative\nyy['FALSE_NEGATIVE'] = np.where((yy.TRUE_POSITIVE==0) & (yy.EQUIPMENT_FAILURE==1), 1, 0)",
            "execution_count": 128,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define a false positive\nyy['BAD_S']=np.where((yy.WARNING<0) | (yy.WARNING>=forecast_window), 1, 0)\n\nyy['FALSE_POSITIVE'] = np.where(((yy.Y_FAILZ == 1) & (yy.BAD_S==1) & (yy.ID_OF_SIGNAL==yy.ID)), 1, 0)",
            "execution_count": 129,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy['bootie']=1",
            "execution_count": 130,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy['CATEGORY']=np.where((yy.FALSE_POSITIVE==1),'FALSE_POSITIVE',\n                                      (np.where((yy.FALSE_NEGATIVE==1),'FALSE_NEGATIVE',\n                                                (np.where((yy.TRUE_POSITIVE==1),'TRUE_POSITIVE','TRUE_NEGATIVE')))))",
            "execution_count": 131,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Define metrics for the testing, training, and validation Data sets."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "table = pd.pivot_table(yy, values=['bootie'], index=['MODELING_GROUP'],columns=['CATEGORY'], aggfunc=np.sum)\ntable",
            "execution_count": 132,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 132,
                    "data": {
                        "text/plain": "                       bootie                                           \nCATEGORY       FALSE_NEGATIVE FALSE_POSITIVE TRUE_NEGATIVE TRUE_POSITIVE\nMODELING_GROUP                                                          \nTESTING                    98            131        108639            51\nTRAINING                   41            107        106473           105\nVALIDATION                 79             98         91882            47",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">bootie</th>\n    </tr>\n    <tr>\n      <th>CATEGORY</th>\n      <th>FALSE_NEGATIVE</th>\n      <th>FALSE_POSITIVE</th>\n      <th>TRUE_NEGATIVE</th>\n      <th>TRUE_POSITIVE</th>\n    </tr>\n    <tr>\n      <th>MODELING_GROUP</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>TESTING</th>\n      <td>98</td>\n      <td>131</td>\n      <td>108639</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>TRAINING</th>\n      <td>41</td>\n      <td>107</td>\n      <td>106473</td>\n      <td>105</td>\n    </tr>\n    <tr>\n      <th>VALIDATION</th>\n      <td>79</td>\n      <td>98</td>\n      <td>91882</td>\n      <td>47</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Remember this chart?\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from IPython.display import Image\nfrom IPython.core.display import HTML \nImage(url= \"https://cdn-images-1.medium.com/max/1600/1*fUKUEUeqgIYU9xlxj4pwhw.png\")",
            "execution_count": 133,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 133,
                    "data": {
                        "text/html": "<img src=\"https://cdn-images-1.medium.com/max/1600/1*fUKUEUeqgIYU9xlxj4pwhw.png\"/>",
                        "text/plain": "<IPython.core.display.Image object>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "A false positive is \u201cUnnecessary Maintenance.\u201d \nA true positive is a \u201cTimely and Appropriate Maintenance.\u201d \nA false negative is \u201cMachine Runs to Failure.\u201d \n\nThis means that a false positive costs $1,500.   \n\nA false negative costs $30,000.   \n\nA true positive costs $7,500. \n\nA true negative has no cost because no action is taken.\n\nNow we can calculate the total cost."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy['TOTAL_COST']=yy.FALSE_NEGATIVE*30000+yy.FALSE_POSITIVE*1500+yy.TRUE_POSITIVE*7500",
            "execution_count": 134,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Aggregate the costs by modeling group."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\ntable = pd.pivot_table(yy, values=['TOTAL_COST'],index=['MODELING_GROUP'], aggfunc=np.sum)\ntable",
            "execution_count": 135,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 135,
                    "data": {
                        "text/plain": "                TOTAL_COST\nMODELING_GROUP            \nTESTING            3519000\nTRAINING           2178000\nVALIDATION         2869500",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TOTAL_COST</th>\n    </tr>\n    <tr>\n      <th>MODELING_GROUP</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>TESTING</th>\n      <td>3519000</td>\n    </tr>\n    <tr>\n      <th>TRAINING</th>\n      <td>2178000</td>\n    </tr>\n    <tr>\n      <th>VALIDATION</th>\n      <td>2869500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Calculate the number of machines in each modeling group."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "wells=yy[['ID','MODELING_GROUP']]",
            "execution_count": 136,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "wells=wells.drop_duplicates(subset='ID')\n\nwells.shape",
            "execution_count": 137,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 137,
                    "data": {
                        "text/plain": "(421, 2)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "wells = wells.groupby(['MODELING_GROUP'])['ID'].count()\nwells=pd.DataFrame(wells)\nwells=wells.rename(columns={\"ID\": \"WELLS\"})",
            "execution_count": 138,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "wells",
            "execution_count": 139,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 139,
                    "data": {
                        "text/plain": "                WELLS\nMODELING_GROUP       \nTESTING           149\nTRAINING          146\nVALIDATION        126",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WELLS</th>\n    </tr>\n    <tr>\n      <th>MODELING_GROUP</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>TESTING</th>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>TRAINING</th>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>VALIDATION</th>\n      <td>126</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Merge the total costs and total machines into one data frame."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "tc = yy.groupby(['MODELING_GROUP'])['TOTAL_COST'].sum()\ntc=pd.DataFrame(tc)\n",
            "execution_count": 140,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Calculate the average cost per machine."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ac =tc.merge(wells, on=['MODELING_GROUP'], how='inner')\n",
            "execution_count": 141,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ac['AVERAGE_COST']=ac.TOTAL_COST/ac.WELLS\nac['LIFT']=27948-ac.AVERAGE_COST",
            "execution_count": 142,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "ac",
            "execution_count": 143,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 143,
                    "data": {
                        "text/plain": "                TOTAL_COST  WELLS  AVERAGE_COST          LIFT\nMODELING_GROUP                                               \nTESTING            3519000    149  23617.449664   4330.550336\nTRAINING           2178000    146  14917.808219  13030.191781\nVALIDATION         2869500    126  22773.809524   5174.190476",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TOTAL_COST</th>\n      <th>WELLS</th>\n      <th>AVERAGE_COST</th>\n      <th>LIFT</th>\n    </tr>\n    <tr>\n      <th>MODELING_GROUP</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>TESTING</th>\n      <td>3519000</td>\n      <td>149</td>\n      <td>23617.449664</td>\n      <td>4330.550336</td>\n    </tr>\n    <tr>\n      <th>TRAINING</th>\n      <td>2178000</td>\n      <td>146</td>\n      <td>14917.808219</td>\n      <td>13030.191781</td>\n    </tr>\n    <tr>\n      <th>VALIDATION</th>\n      <td>2869500</td>\n      <td>126</td>\n      <td>22773.809524</td>\n      <td>5174.190476</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "###  8.0 Conclusions <a id=\"conc\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now we have everything we need to examine the effectiveness of the model.  \n\nMaintenance currently costs the firm about 27,948 dollars per machine in the current data set. In the Validation data set, the cost per machine is 22,773.81.  This means a predictive maintenance solution will lower the cost per machine by about 5,174 dollars per machine.  Multiplied by 421 machines, the equates to a 2.17 Millon saving or an 18% reduction in total expenses.\n\nNot too shabby.\n\nOne final note. There are many judgments I made that work for this example but may not work for you. Unfortunately, there is no \u201cone size fits all\u201d solution for any data science problem.\n\nNonetheless, this exercise should give you a useful reference as you approach these types of problems in the future.\n\nAs far as the next steps, I would encourage you to see if you can improve the solution by optimizing the model. Maybe incorporate some hyper-parameter optimization or even try a different model. Let me know how it turns out!\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Author\n\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "\n**Shad Griffin**, is a Certified Thought Leader and Data Scientist at IBM"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<hr>\nCopyright &copy; IBM Corp. 2020. This notebook and its source code are released under the terms of the MIT License.\n\n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}